\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cite}

\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem*{remark}{Remark}

%---------------------------------------------------------------

\title{The expected number of contigs}
\author{
\textsc{Guillaume Filion} \\ [1ex]
\normalsize CRG, Barcelona
}
\date{\today}

%---------------------------------------------------------------
%---------------------------------------------------------------


\begin{document}

\maketitle

\begin{abstract}
Here is the text of the abstract. I need to type more in order to see if
this goes beyond the two columns of the text.
\end{abstract}


%---------------------------------------------------------------
%---------------------------------------------------------------

\section{Introduction}

How many reads should I sequence? How long should they be? With what
minimum overlap? These questions were first addressed in this context by
Lander and Waterman in a landmark study that defined the ``classic
theory'' of assembly \cite{pmid3294162}, giving estimates of the number of
contigs. At the time, genome assembly was a long term endeavour and it
made sense to gather information about the progress of the project. The
Lander-Waterman estimators are thus accurate for intermediate stages where
the number of contigs is high, but their quality drops when the assembly
nears completion.

Nowadays, genome assembly is several orders of magnitude faster. The
questions remain the same, but in many cases the assembly does not have a
proper intermediate stage because the sequencing capacity of a single run
is potentially sufficient to assemble the target genome. It is thus
desirable to minimize the amount of resources that a necessary for the
task, and estimators that are accurate when assembly is likely to be
possible are generally more useful. Likewise, the parameters of the
algorithm must minimize the risk of misassembly while giving the highest
chance that assembly will be possible. This can be done efficiently only
if the statistical properties of the assembly are also understood when it
is likely to be possible.

These are asymptotic estimates, which means that unlike the classical
estimators, they get more accurate when the number of reads increases. In
practice, they are accurate to within 1\% even for a few hundred reads
taken from a genome of a few hunder nucleotides.

All the results shown here are based on original proofs using analytic
combinatorics \cite{AnalComb2009}. The general strategy of analytic
combinatorics is to (i) describe simple combinatorial objects by a
generating function (ii) use simple mathematical operations to find the
generating function of complex structures based on these objects and (iii)
analyze the singularities of the resulting function to derive asymptotic
estimates. This method is sometimes considered counter-intuitive because
generating functions do not directly appeal to intuition
\cite{AnalComb1996}, but it allows to derive precise estimates with simple
proofs.

Since I expect most readers to not be familiar with analytic
combinatorics, I have tried to introduce the ideas progressively, hoping
that the logic of each step will be apparent. This also means that the
information is somewhat spread throughout the manuscript and does not
clearly separate the biological and the mathematical concepts. I have also
tried to use standard notations from analytic combinatorics for the proofs
of the claims, and standard notations from genomic for the specific
applications, which may be slightly confusing.  The key findings are
applications of recent results of Pemantle and Wilson on multivariate
asymptotics. The reader is referred to the original literature for the
proofs of those theorems \cite{PemWil08,AnalComb2013}.

\textbf{Related work:} Schbath and collaborators \cite{pmid10890387}
studied the effect of varying read length on the distribution of contigs.
Wendl \cite{pmid16901236} developed a theory taking into account ``edge
effects'' appearing when the read length is not negligible compared to the
size of the target genome. Stanhope \cite{pmid20686599} studied the
distribution of the largest contig using models of occupancy.


\section{Results}

\subsection{Analytic combinatorics of the assembly problem}
\label{sec:config}

If $(a_{k,n})_{k \geq 0, n \geq 0}$ is a bivariate array, the generating
function of the array is by definition

\begin{equation*}
F(x,y) = \sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n}x^ky^n.
\end{equation*}

When $a_{k,n}$ counts the number of objects in a set $\mathcal{A}$, we
will say that $F(x,y)$ is the generating function of those objects. When
the emphasis is on the generating function, will refer to $a_{k,n}$ as the
``coefficient of $x^ky^n$ in $F(x,y)$'', and denote it as ``$[x^ky^n]
F(x,y)$'' when convenient. The function $F$ and the bivariate sequence
$(a_{k,n})_{k \geq 0, n \geq 0}$ carry the same information, but some
combinatorial operations are easier to perform with $F$, as we will see
below.

The first combinatorial object that we will consider is the ``interval'',
defined here as the distance between the left ends of two consecutive
reads. We will call this distance the \emph{size} of the interval, and we
will impose it to be a strictly positive integer. This means that two
reads cannot map to the same location, but we will later see how to relax
this constraint. We will also give each interval a \emph{weight} equal to
$1$. This may seem odd, but it will allow us to count intervals when we
create more complex objects.

\begin{remark}
In the fields of combinatorics, the coverage of $k$ nucleotides by $n$
intervals corresponds to a composition, \textit{i.e.} the break-down of
$k$ as a sum of $n$ positive integers \cite{AnalComb2009}. All the results
presented in this article can be interpreted more widely as properties of
compositions.
\end{remark}

We will use analytic combinatoric to derive asymptotic estimates in a
context where the results will be familiar. For this, we need to obtain
the generating function of intervals. There is exactly one interval of
size $k$ and weight 1 ($k > 0$), and zero interval in all other cases, so
$a_{k,n} = 1$ if $n = 1$ and $k > 0$, and $a_{k,n} = 0$ otherwise. The
generating function of intervals is thus

\begin{equation}
\label{eq:F}
F(x,y) = xy + x^2y + x^3y + \ldots
= xy(1+x+x^2+\ldots) = \frac{xy}{1-x}.
\end{equation}

In this expression, we say that $x$ ``marks'' the size and that $y$
``marks'' the weight.

Operations on generating functions allow us to create more complex
combinatorial objects through mathematical operations.  We have already
used additions, which corresponds to disjoint unions. For instance, the
generating function above says that an interval is either an interval of
size 1 and weight 1, or an interval of size 2 and weight 1, or an interval
of size 3 and weight 1 \textit{etc}. More generally, if $Q(x,y)$ and
$R(x,y)$ are the generating functions of objects in disjoint sets
$\mathcal{Q}$ and $\mathcal{R}$, then $Q(x,y)+R(x,y)$ is the generating
function of objects in $\mathcal{Q} \cup \mathcal{R}$.

Multiplications correspond to Cartesian products. More specifically, if
$Q(x,y)$ and $R(x,y)$ are the generating functions of objects in sets
$\mathcal{Q}$ and $\mathcal{R}$ (disjoint or not), then $Q(x,y)R(x,y)$ is
the generating function of objects in $\mathcal{Q} \times \mathcal{R}$,
provided the attributes are \emph{additive}. For instance, we can take
both $\mathcal{Q}$ and $\mathcal{R}$ as the set of intervals. If we define
the size of a pair of intervals as the sum of their sizes (by placing the
ends next to each other) and its weight as 2, then size and weight are
additive, so the generating function of pairs of intervals is $Q(x,y)^2$.

To see this, observe that the pairs of intervals of size $k$ and weight
$n$ are made of all pairwise combinations of intervals whose sizes sum to
$k$ and weights sum to $n$. The number of such pairs is $\sum_{l=0}^k
\sum_{m=0}^n q_{l,m}q_{k-l,n-m}$ so the generating function is

\begin{equation*}
\begin{split}
\sum_{k=0}^\infty &\sum_{n=0}^\infty \left( \sum_{l=0}^k \sum_{m=0}^n
  q_{l,m}q_{k-l,n-m}\right) x^k y^n \\
&= \sum_{l=0}^\infty \sum_{m=0}^\infty \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{l,m}q_{k-l,n-m}x^{l + k-l} y^{m + n-m} \\ 
&= \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
  \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{k-l,n-m}x^{k-l} y^{n-m} \\
&= Q(x,y) \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
 = Q(x,y)Q(x,y).
\end{split}
\end{equation*}


Applying the formula above multiple times, we see that if $A(x,y)$ is the
generating function of objects in $\mathcal{A}$, then $A(x,y)^n$ is the
generating function of objects in $\mathcal{A}^n$ (representing $n$-tuples
of objects in $\mathcal{A}$). Since joining $n$ consecutive intervals
gives a new interval whose size is the sum of individual sizes and whose
weight is the number of (atomic) intervals, $I(x,y)^n$ is the generating
function of the concatenation of $n$ intervals. It follows that the
generating function of all joined intervals is

\begin{equation}
\begin{split}
\label{eq:C}
C(x,y) &= \sum_{n=0}^\infty \left( \frac{xy}{1-x} \right)^n
= \frac{1}{1 - xy/(1-x)} \\
&= \frac{1-x}{1-x(1+y)} = (1-x) \sum_{k=0}^\infty \left(x(1+y) \right)^k.
\end{split}
\end{equation}

Using Newton's binomial formula, we can easily obtain an explicit
expression for the coefficients of $C(x,y)$, namely

\begin{equation*}
C(x,y) = (1-x)\sum_{k=0}^\infty x^k\sum_{n=0}^k {k \choose n} y^n
= \sum_{k=0}^\infty\sum_{n=0}^\infty{k \choose n} (x^ky^n - x^{k+1}y^n).
\end{equation*}

It follows that

\begin{equation}
\label{eq:coefC}
[x^ky^n] C(x,y) =
{k \choose n} - {k-1 \choose n} = {k-1 \choose n-1}
\text{, provided $k > 0$, $n > 0$}.
\end{equation}

In the cases not covered by formula (\ref{eq:coefC}), the coefficients are
equal to 0, except for $k = n = 0$ where the coefficient is equal to 1.

\begin{remark}
The last expression in (\ref{eq:C}) gives an alternative construction for
sequences of intervals. The term $1+y$ is the generating function of bits,
\textit{i.e.} elements of $\{0,1\}$, so $(x(1+y))^k$ is the generating
function of bit strings where $x$ marks the size. Sequences of intervals
are equivalent to bit strings, because we can encode left end of intervals
with a $1$ and every other position with a $0$.
\end{remark}

In this example, we were able to obtain an explicit expression for the
number of ways that $n$ intervals can cover $k$ nucleotides. We could use
Stirling's formula to obtain the asymptotic behavior of those
coefficients, but in general this information is directly available from
the generating function, especially when it has a simple form such as
(\ref{eq:C}).

Riordan arrays are bivariate arrays $(a_{k,n})_{k,n}$ such that the
generating function satisfies

\begin{equation*}
\sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n} x^k y^n =
\frac{\phi(x)}{1-y \nu(x)}.
\end{equation*}

\begin{proposition}
\label{th:PW}
Assume that $F(x,y)$ is the generating function of a Riordan array, and
that $k$ and $n$ tend to infinity with $\lim k/n = \lambda$, then

\begin{equation}
\label{eq:assRA}
[x^ky^n]F(x,y) \sim \frac{\nu(x_\lambda)^n\phi(x_\lambda)}
  {x_\lambda^k\sqrt{2\pi n \sigma(x_\lambda)^2}},
\end{equation}

\noindent
where $x_\lambda$ is the solution of $\mu(x) = x\nu'(x)/\nu(x) = \lambda$
and where $\sigma(x)^2 = x \mu'(x)$.
\end{proposition}

In essence, proposition \ref{th:PW} says that if $k \sim \lambda n$ and if
we can find the solution of the equation $\mu(x) = \lambda$, then we get
the asymptotic growth of the Riordan array $a_{k,n}$. The proof of this
theorem is outside the scope of this article, the interested reader is
referred to the original results of Pemantle and Wilson
\cite{PemWil08,AnalComb2013}.

Expression (\ref{eq:C}) shows that $C(x,y)$ is the generating function of
a Riordan array with $\phi(x) = 1$ and $\nu(x) = x/(1-x)$.  Here $\mu(x) =
1/(1-x)$ and $\sigma^2(x) = x/(1-x)^2$, so we obtain $x_\lambda = (\lambda
-1)/\lambda$, $\nu(x_\lambda) = \lambda -1$, and $\sigma^2(x_\lambda) =
\lambda(\lambda-1)$. Combining this with $\lambda \sim k/n$ we obtain

\begin{equation}
\label{eq:assBC}
{k-1 \choose n-1} \sim \frac{k^{k-1}}{n^{n-1}(k-n)^{k-n}}
\sqrt{\frac{k}{2\pi n(k-n)}}.
\end{equation}

This section illustrates the strategy of analytic combinatorics: we
specify combinatorial structures through generating functions, and we use
general theorems to extract coefficient asymptotics. This approach may
seem counter-intuitive or overly complex, but we will see in the next
sections how it can lead to results that are otherwise not available. 

\subsection{Probability of tight coverage}
\label{sec:compass}

% This is where I define tight coverage.
In the shotgun strategy of genome assembly, reads are merged if they
overlap by some minimum amount of nucleotides. The process continues with
consecutive reads in both directions, as long as they overlap by this
minimum amount of nucleotides. The merged sequences are called
\emph{contigs}, and the assembly of a chromosome is theoretically possible
if it consists of a single contig (in practice, the fact that biological
sequences are interspersed with repeats makes assembly more difficult). We
call this event ``tight coverage'', and it is interesting to determine
its \textit{a priori} probability.

From here on, $d$ will denote the maximal allowed distance between the
left ends of consecutive reads that can be merged. Note that the minimum
amount of nucleotides that reads must overlp is $L-d$, where $L$ is their
length. We also introduce intervals of size no greater than $d$ and call
them ``$d$-intervals''. Since the case $d=1$ is trivial, we will assume $d
> 1$ throughout.

Following the same rationale as bove, we first need to find the generating
function of $d$-intervals. This is done easily by stopping the sum in
(\ref{eq:F}) after $x^dy$, so we obtain $F_d(x,y) = (x+x^2+\ldots+x^d)y$.
Since a contig is a sequence of $d$-intervals, the generating function of
contigs is

\begin{equation}
\label{eq:Cd}
C_d(x,y) = \sum_{n=0}^\infty \left(y(x+x^2+\ldots+x^d)\right)^n =
\frac{1}{1-y(x+x^2+\ldots+x^d)}.
\end{equation}

The coefficients of $C_d(x,y)$ are known as the polynomial coefficients,
but they cannot be expressed in closed form. However, this is not an issue
because (\ref{eq:Cd}) is the generating function of a Riordan with
$\phi(x) = 1$ and $\nu(x) = x + x^2 + \ldots + x^d$, so we can extract
their asymptotic behavior from proposition \ref{th:PW}.

\begin{lemma}
\label{th:mu}
For $\nu(x) = x+x^2+\ldots+x^d$, the equation $\mu(x) = x\nu'(x)/\nu(x) =
\lambda$ has a single solution $x_\lambda$ for $1 \leq \lambda \leq d$.
\end{lemma}

\begin{proof}
We first demonstrate that for $x \geq 0$, $\mu$ is strictly increasing.
This will ensure that if the solution is unique if it exists.

\begin{equation}
\label{eq:mu}
\mu(x) = x\frac{\nu'(x)}{\nu(x)} =
\frac{x+2x^2+3x^3+\ldots+dx^d}{x+x^2+\ldots+x^d} =
d+\frac{1}{1-x} - \frac{d}{1-x^d}.
\end{equation} 

Differentiating the last expression we obtain

\begin{equation}
\label{eq:muprime}
\mu'(x) = \frac{1}{(1-x)^2} -\frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{equation}

The function $f(\alpha) = x^{\alpha} = e^{\alpha \log(x)}$ is strictly
convex for every $x > 0$ and $x \neq 1$. Applying the definition of
convexity, we obtain the inequality

\begin{eqnarray*}
\frac{f(0)+\ldots+f(d-1)}{d} &>&
f\left(\frac{0+1+2+\ldots+d-1}{d}\right) \\
\frac{1+x+\ldots+x^{d-1}}{d} &>& f\left(\frac{d-1}{2}\right)
= x^{(d-1)/2} \\
\frac{1-x^d}{1-x} &>& dx^{(d-1)/2} \\
\frac{1}{(1-x)^2} &>& \frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{eqnarray*}

Combined with equation (\ref{eq:muprime}), the last inequality shows that
$\mu'(x) > 0$ for $x > 0$ and $x \neq 1$. Since $\mu'(0) = 1$ and $\mu'(1)
= (d+1)(d-1)/12$, $\mu$ is strictly increasing (note that $\mu'(1)$ is
properly defined but that $\mu'(0)$ must be defined by continuity).
Observing that $\mu(0) = 1$ and $\lim_{x\rightarrow\infty} \mu(x) = d$,
the equation $\mu(x) = \lambda$ has a unique solution provided $1 \leq
\lambda \leq d$.
\end{proof}

\begin{remark}
The cases $\lambda > d$ and $\lambda < 1$ correspond to limits where $k >
nd$ and $k < n$, respectively. Since the size of a collection of $n$
$d$-intervals is between $n$ and $nd$, we have the trivial asymptotic
behavior $a_{k,n} = 0$ in both cases.
\end{remark}


The value of $x_\lambda$ can be found numerically using expression
(\ref{eq:mu}).  Once it is available, we can compute $\nu(x_\lambda)$ and
$\sigma(x_\lambda^2)$ from their definitions, but numeric precision can
become an issue if $n$ or $d$ is very large. To avoid this, we can use the
equivalent expressions


\begin{gather}
\label{eq:nu} %% Equation for nu.
\nu(x_\lambda) = \frac{dx_\lambda}{1+(d-\lambda)(1-x_\lambda)}, \\
\label{eq:sigma} %% Equation for sigma2.
\sigma(x_\lambda)^2 = \lambda(d-\lambda) -
  \frac{d-2\lambda+1}{1-x_\lambda}.
\end{gather}

The coefficients of $C(x,y)$ give the total number of configurations, and
those of $C_d(x,y)$ give the number of configurations with a single
contig. The probability that a chromosome can be assembled is thus
$[x^ky^n] C_d(x,y) / [x^ky^n] C(x,y)$, which can be approximated with the
asymptotic formulas developed above.

\begin{example}
Let us consider a genome of size 25,001. We assume that 10,001 reads are
drawn uniformly at random without replacement. This translates into
$k=25000$ and $n=10000$. Setting the maximum distance between reads in a
contig to $d=25$, what is the probability that the genome can be
assembled?

First, we get $\lambda = k/n = 2.5$. We then solve equation (\ref{eq:mu})
with the Newton-Raphson method and obtain $x_\lambda \approx 0.600011377$.
Using equations (\ref{eq:nu}) and (\ref{eq:sigma}) we obtain
$\nu(x_\lambda) \approx 1.50006684$ and $\sigma(x_\lambda)^2 \approx
3.747554$. We compute equation (\ref{eq:assRA}) in logarithmic space and
obtain

\begin{equation*}
\begin{split}
10000&\log(1.50006684) - 25000\log(0.600011377) \\
- &\log(10000)/2 - \log(3.747554)/2 - \log(2\pi)/2
\approx 16819.0786.
\end{split}
\end{equation*}

We also compute 

\begin{equation*}
\log { 24999 \choose 9999 } \approx 16819.1067.
\end{equation*}

The estimated probability that a configuration corresponds to a coverage
by $25$-intervals is thus

\begin{equation*}
\exp(16819.0783-16819.1067) \approx 0.972.
\end{equation*}

Randomly sampling 200,000 configurations gives an estimate for this
probability equal to $0.972$, close to the numerical approximation by
three digits. In this example, $x_\lambda$ and $\nu(x_\lambda)$ must be
approximated to eight digits in order to obtain an approximate accurate to
within 1\%. Using the definition of $\nu$ instead of (\ref{eq:nu}), we
would obtain an estimate equal to $0.983$. The difference is negligible
here, but on real problems, $n$ and $k$ can be several orders of magnitude
higher, which will increase the difference.
\end{example}

In the above, we have assumed that all the reads map to different
locations. It is possible to enforce this by removing duplicate reads, but
it would be more useful to estimate the probability that the chromosome
can be assembled before resources are spent. 

Assume that there is a total of $n_*$ reads and that they are drawn with
replacement. Each nucleotide of the chromosome corresponds to the left end
of a read $n_*/k$ times on average. Because $k$ and $n$ are both large, we
can approximate the number of time a nucleotide is drawn by a Poisson
distribution with mean $n_*/k$. The probability that a position is not
sampled is approximately $e^{-n_*/k}$ so that the frequency of sampled
positions is $1-e^{-n_*/k}$. The strategy is thus to replace the true
number of reads by the expected number of distinct reads

\begin{equation}
\label{eq:nstar}
n = k(1-e^{-n_*/k}).
\end{equation}


\begin{example}
We consider the same problem as in the previous example, with a genome of
size 25,001 and 10,001 reads at a maximum distance of 25 ncleotides, but
this time the reads are drawn uniformly at random with replacement. As
above, $k=25000$, but we need to replace $n$ by $25000 \cdot
(1-e^{-10000/25000}) \approx 8241.9988$.

We now obtain $\lambda = k/n \approx 3.033$. Following the same
calculations as in the previous example, we obtain $x_\lambda \approx
0.67044394$, $\nu(x_\lambda) \approx 2.03429230$ and
$\sigma(x_\lambda)^2 \approx 6.144599$. Computing (\ref{eq:assRA}) in
logarithmic space with the new values yields

\begin{equation*}
\begin{split}
8241.9988\log(2.03429230) - &25000\log(0.67044394) \\
- \log(8241.9988)/2 - &\log(6.144599)/2 - \log(2\pi)/2
\approx 15842.084.
\end{split}
\end{equation*}

Likewise, we also have

\begin{equation*}
\log { 24999 \choose 8240.9988 } \approx 15842.457.
\end{equation*}

Finally, the estimated probability that a configuration corresponds to a
coverage by $25$-intervals is

\begin{equation*}
\exp(15842.084-15842.457) \approx 0.689.
\end{equation*}

Randomly sampling 200,000 configurations gives an estimate for this
probability equal to $0.688$. This is less accurate than in the previous
example, but still within 1\% of the real value.
\end{example}

In conclusion, we can continue to assume that reads are all distinct, and
use formula (\ref{eq:nstar}) whenever the assumption does not hold.

\begin{remark}
Allowing intervals and $d$-intervals to have size $0$ is not the proper
way to address this issue because it gives a different sampling scheme.
For $4$ reads covering $2$ nucleotides (\textit{i.e.} $k=1$ and $n=3$),
the probability that the first two intervals have size $0$ would be $1/3$,
whereas it should be $2/7$.
\end{remark}

In summary, estimates of the chances of success of the assembly are
accurate in the range where they are the most useful, namely when the
value is not exceedingly close to 0 or to 1. The steps required to
automate the estimation are recapitulated here:

\begin{enumerate}
\item Compute the expected number of distinct reads $n$ using
(\ref{eq:nstar}). 
\item Compute $\lambda = k/n$.
\item Solve $\mu(x_\lambda) = \lambda$ by the Newton-Raphson method using
(\ref{eq:mu}) and (\ref{eq:muprime}).
\item Compute $\nu(x_\lambda)$ and $\sigma^2(x_\lambda)$ using
(\ref{eq:nu}) and (\ref{eq:sigma}).
\item Compute (\ref{eq:assRA}) in logarithmic space.
\item Compute (\ref{eq:coefC}) in logarithmic space.
\item Take the difference of the last two terms and exponentiate.
\end{enumerate}

\subsection{The average number and size of contigs}
\label{sec:av}

If the coverage is not tight, it is interesting to know the expected
number of contigs and their expected size. For this, we need to introduce
``$d$-gaps'', that are intervals of size greater than $d$. By definition,
contigs are flanked by $d$-gaps so we can count the $d$-gaps and  infer
the number of contigs.

The generating function of $d$-gaps is $x^{d+1}y + x^{d+2}y + \ldots =
yx^{d+1}/(1-x)$. Note that an interval is either a $d$-interval or a
$d$-gap, and since a configuration is a sequence of intervals, we can
write their generating function as

\begin{equation}
\label{eq:C2ndform}
C(x,y) = \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
y\frac{x^{d+1}}{1-x}\right)^n.
\end{equation}

It is elementary to verify that this expression is equivalent to
(\ref{eq:C}). We can use it to mark the number of gaps by the variable
$u$. The same was as multiplying the generating function of intervals by
$y$ ensured that the coefficient of $y^n$ indicates the number of
configurations with $n$ intervals, we multiply the generating function of
$d$-gaps by $u$, so that the coefficient of $u^m$ indicates the number of
configurations with $m$ $d$-gaps.

\begin{equation*}
H(x,y,u) = \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
uy\frac{x^{d+1}}{1-x}\right)^n
= \frac{1-x}{1-x-y\left(x(1-x^d) +ux^{d+1}\right)}.
\end{equation*}

$H(x,y,u)$ is the generating function of a three-dimensional array
$(a_{k,n,m})$, where each term is the number of configurations of total
size $k$, total weight $n$ and with $m$ $d$-gaps. Note that both
$d$-intervals and $d$-gaps contribute to the weight, so that it still
indicates the number of distinct reads. For a given value of $k$ and $n$,
the cumulative number of $d$-gaps is $\sum_{m=0}^\infty ma_{k,n,m}$. Since
for the same values of $k$ and $n$ the total number of configurations is
$\sum_{m=0}^\infty a_{k,n,m}$ the average number of $d$-gaps is

\begin{equation}
\label{eq:average}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m}.
\end{equation}

As usual, we will find the generating functions for the numerator and the
denomiator of (\ref{eq:average}) and use proposition \ref{th:PW} to obtain
asymptotic estimates. Observe that

\begin{equation*}
\begin{split}
\frac{\partial H(x,y,u)}{\partial u}\Bigr|_{\substack{\\u=1}} &=
\sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty ma_{k,n,m}\right) x^ky^n \text{, and} \\
H(x,y,1) &= \sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty a_{k,n,m} \right)x^ky^n.
\end{split}
\end{equation*}

This implies that we can compute (\ref{eq:average}) from the coefficients
of $H(x,y,u)$ and its partial derivative at $u=1$. It is easier to start
with the denominator as the results are already available. Equation
(\ref{eq:C2ndform}) implies that $H(x,y,1) = C(x,y)$. We could extract the
coefficients as per expression (\ref{eq:coefC}) and proceed as in the
previous section, but we can obtain a much simpler result as will appear
shortly. Now turning to the numerator we obtain

\begin{equation*}
\frac{\partial H(x,y,u)}{\partial u}\Bigr|_{\substack{\\u=1}}
= \frac{yx^{d+1}(1-x)}{\left(1-x-xy\right)^2}.
\end{equation*}

Careful attention shows that this expression is ``almost'' the generating
function of a Riordan array. Observe that

\begin{equation*}
\frac{\partial C(x,y)}{\partial y} = 
\frac{x(1-x)}{\left(1-x-yx\right)^2}.
\end{equation*}

So $\partial H(x,y,u)/\partial u|_{\substack{\\u=1}} = yx^d\partial
C(x,y)/\partial y$, and since $\lim k/n = \lambda$ implies $\lim (k-d)/n =
\lambda$, we can use proposition \ref{th:PW} to derive asymptotics for the
numerator of (\ref{eq:average}). More significantly, the ratio is now
greatly simplified:

\begin{equation*}
\frac{[x^ky^n] \partial H(x,y,u)/\partial u|_{\substack{\\u=1}}}
{[x^ky^n]H(x,y,1)} =
\frac{n[x^{k-d}y^n]C(x,y)}{[x^ky^n]C(x,y)}
\sim n x_\lambda^d.
\end{equation*}

We have seen in section \ref{sec:config} that $x_\lambda =
(\lambda-1)/\lambda$, so the average number of $d$-gaps is
$n(1-1/\lambda)^d$, which we can express in the more general form

\begin{equation*}
n\left(1-n/k\right)^d.
\end{equation*}

Recall that this formula assumes that reads are distinct (which implies
among others that $n \leq k$). In order to obtain the average number of
$d$-gaps when reads are not assumed to be distinct, we use expression
(\ref{eq:nstar}) and obtain

\begin{equation}
\label{eq:avstar}
k(1-e^{-n_*/k})e^{-n_*d/k}.
\end{equation}

\begin{example}
Consider the same examle as above, with a genome of size 25,001 and 10,001
reads drawn uniformly at random with replacement (\textit{i.e.} $k =
25000$ and $n_* = 10000$. Formula (\ref{eq:avstar}) immediately yields an
average equal to 0.374.

Randomly sampling 200,000 configurations gives an estimate for this
average equal to $0.375$, again within 1\% of the estimate.
\end{example}

When the number of $d$-gaps is small, we can just add $1$ to obtain an
estimate for the number of contigs. However, at low coverage the first or
the last interval may be a $d$-gap, or two $d$-gaps may lie next to each
other, so the approximation will overstimate the number of contigs. In
such cases, we need to count contigs directly, which is slightly more
tedious.

In the above, the function $H(x,y,u)$ is a ``counting function'' and $u$
is the ``counting parameter''. We can count any object, including contigs,
by decorating their generating function with $u$. As above, the average
number of those objects in configurations of size $k$ and weight $n$ will
be given by the ratio

\begin{equation*}
\frac{[x^ky^n] \partial H(x,y,u)/\partial u|_{\substack{\\u=1}}}
{[x^ky^n]H(x,y,1)}.
\end{equation*}

We can thus exhibit the counting function of contigs and use the same
method as above. It is intuitively clear that configurations consist of
non-empty sequences of contigs and non-empty sequences of $d$-gaps.
Non-empty contigs are non-empty sequences of $d$-intervals, so their
generating function is

\begin{equation*}
C_{d*}(x,y) = \sum_{n=1}^\infty \left(yx\frac{1-x^d}{1-x} \right)^n
= \frac{yx(1-x^d)/(1-x)}{1-yx(1-x^d)/(1-x)}.
\end{equation*}

Similarly, the generating function of non-empty sequences of $d$-gaps is

\begin{equation*}
G_{d*}(x,y) = \sum_{n=1}^\infty \left(y\frac{x^{d+1}}{1-x} \right)^n
= \frac{yx^{d+1}/(1-x)}{1-yx^{d+1}/(1-x)}.
\end{equation*}

The basic unit of configurations is a non-empty contig followed by a
non-empty sequence of $d$-gaps, whose generating function is
$uC_{d*}(x,y)G_{d*}(x,y)$. The presence of $u$ here indicates that each
unit adds 1 to the count of contigs. A configuration is a sequence of such
units, but it starts with a potentially empty sequence of $d$-gaps, whose
generating function is $1+G_{d*}(x,y)$, and it ends with a potentially
empty contig, whose generating function is $1+uC_{d*}(x,y)$. The counting
function thus comes out as

\begin{equation*}
\begin{split}
H(x,y,u) &= \left( 1+G_{d*}(x,y) \right)
\left( \sum_{n=0}^\infty (uC_{d*}(x,y)G_{d*}(x,y))^n \right)
\left( 1+uC_{d*}(x,y) \right) \\
& = \frac{(1+G_{d*}(x,y))(1+uC_{d*}(x,y))}{1-uC_{d*}(x,y)G_{d*}(x,y)}.
\end{split}
\end{equation*}

One can check from the definitions of $C_{d*}$ and $G_{d*}$ that $H(x,y,1)
= C(x,y)$ as expected. After a similar calculation as above, we would
obtain

\begin{equation*}
\partial H(x,y,u)/\partial u|_{\substack{\\u=1}}
= y(1-x^d) \frac{\partial C}{\partial y} - y^2\frac{x}{1-x}(1-x^d)^2
\frac{\partial C}{\partial y}.
\end{equation*}

Applying proposition \ref{th:PW} once again, we obtain after some basic
manipulations

\begin{equation}
\frac{[x^ky^n] \partial H(x,y,u)/\partial u|_{\substack{\\u=1}}}
{[x^ky^n]H(x,y,1)} \sim n(1-x_\lambda^d) - (n-1)(1-x_\lambda^d)^2.
\end{equation}

After substituting $x_\lambda$ by $(\lambda-1)/\lambda = 1-n/k$, the
asymptotic average number of contigs for a configuration of size $k$ and
weight $n$ appears as

\begin{equation}
\label{eq:avcont}
\begin{split}
\left( 1+(n-1)(1-n/k)^d \right) \left(1-(1-n/k)^d\right) \text{, or} \\
\left( 1 + k(1-e^{-n_*/k})e^{-n_*d/k} \right) (1+e^{-n_*d/k}).
\end{split}
\end{equation}

Both formulas show the estimate mentioned above (1 plus the number of
$d$-gaps) mutiplied by and a correction factor. For large $n$ or $n_*$ the
correction factor is close to 1 and can be neglected.  Note that in the
second expression, $n-1$ has been replaced by $n$ before applying
(\ref{eq:nstar}). This yields a simpler expression at a negligible cost
for accuracy.

\subsection{The average size of contigs}

It is also interesting to compute the average size of contigs when
coverage is not tight. We can exhibit a counting function for the size of
$d$-intervals and derive asymptotic estimates using the same strategy as
in the previous section. All we have to do is decorate the size of a
$d$-intervals with corresponding powers of $u$ in expression
(\ref{eq:C2ndform}). The decorated generating function of $d$-intervals
becomes $y(xu + x^2u^2 + \ldots x^du^d) = yxu(1-x^du^d)/(1-xu)$. The
counting function is thus

\begin{equation*}
\begin{split}
H(x,y,u) &= \sum_{n=0}^\infty \left(yxu\frac{1-x^du^d}{1-xu} +
y\frac{x^{d+1}}{1-x}\right)^n \\
&= \frac{1}{1-y \left(xu(1-x^du^d)/(1-xu) +
x^{d+1}/(1-x) \right)}.
\end{split}
\end{equation*}

Once again, it is easy to check that $H(x,y,1) = C(x,y)$. Differentiating
with respect to $u$, we obtain

\begin{equation*}
\frac{\partial H(x,y,u)}{\partial u}\Bigr|_{\substack{\\u=1}}
= y \frac{(d+1)x^{d+1}-dx^{d+2}}{(1-x)^2} \frac{\partial C(x,y)}
{\partial y}.
\end{equation*}

%The simplest strategy is to compute the cumulative
%size of $d$-gaps and get the cumulative size of contigs by
%complementarity.
%$y(x^{d+1}u^{d+1} +
%x^{d+2}u^{d+2} + \ldots) = yx^{d+1}u^{d+1}/(1-x^{d+1}u^{d+1})$. The
%counting function thus comes out as
%
%\begin{equation*}
%\begin{split}
%H(x,y,u) &= \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
%y\frac{x^{d+1}u^{d+1}}{1-xu}\right)^n \\
%&= \frac{1}{1-y \left(x(1-x^d)/(1-x) +
%x^{d+1}u^{d+1}/(1-xu) \right)}.
%\end{split}
%\end{equation*}
%
%Once again, it is easy to check that $H(x,y,1) = C(x,y)$. Differentiating
%with respect to $u$, we obtain
%
%\begin{equation*}
%\frac{\partial H(x,y,u)}{\partial u}\Bigr|_{\substack{\\u=1}}
%= y \frac{(d+1)x^{d+1}-dx^{d+2}}{(1-x)^2} \frac{\partial C(x,y)}
%{\partial y}.
%\end{equation*}
%
%From the relation above and from proposition \ref{th:PW}, we obtain the
%asymptotic cumulative size of $d$-gaps as $n(1-1/\lambda)^d(\lambda+d)$.
%Since the expected asymptotic number of $d$-gaps is $n(1-1/\lambda)^d$, we
%see that their individual size is asymptotic to $\lambda+d$ or $k/n+d$, or
%in terms of raw number of reads $1/(1-e^{-n_*/k}) + d$. Intuitively, the
%size of $d$-gaps is very large when $n$ or $n_*$ are much smaller than
%$k$.
%
%To answer the original question, we compute the total size of contigs by
%complementary as $k-n(1-1/\lambda)^d(\lambda+d)$.
%
%\begin{equation}
%\frac{k-(1-k/n)^d(n/k+d)}{1+n(1-n/k)^d}.
%\end{equation}

%---------------------------------------------------------------
%---------------------------------------------------------------

\bibliography{pubmed,extra}
\bibliographystyle{plain}

%----------------------------------------------------------------

\end{document}
