\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cite}

\newtheorem{proposition}{Proposition}
\newtheorem*{remark}{Remark}
\newtheorem{example}{Example}

%---------------------------------------------------------------

\title{The expected number of contigs}
\author{
\textsc{Guillaume Filion} \\ [1ex]
\normalsize CRG, Barcelona
}
\date{\today}

%---------------------------------------------------------------
%---------------------------------------------------------------


\begin{document}

\maketitle

\begin{abstract}
Here is the text of the abstract. I need to type more in order to see if
this goes beyond the two columns of the text.
\end{abstract}


%---------------------------------------------------------------
%---------------------------------------------------------------

\section{Introduction}

How many reads should I sequence? How long should they be? With what
minimum overlap? These questions were first addressed in this context by
Lander and Waterman in a landmark study that defined the ``classic
theory'' of assembly \cite{pmid3294162}, giving estimates of the number of
contigs. At the time, genome assembly was a long term endeavour and it
made sense to gather information about the progress of the project. The
Lander-Waterman estimators are thus accurate for intermediate stages where
the number of contigs is high, but their quality drops when the assembly
nears completion.

Nowadays, genome assembly is several orders of magnitude faster. The
questions remain the same, but in many cases the assembly does not have a
proper intermediate stage because the sequencing capacity of a single run
is potentially sufficient to assemble the target genome. It is thus
desirable to minimize the amount of resources that a necessary for the
task, and estimators that are accurate when assembly is likely to be
possible are generally more useful. Likewise, the parameters of the
algorithm must minimize the risk of misassembly while giving the highest
chance that assembly will be possible. This can be done efficiently only
if the statistical properties of the assembly are also understood when it
is likely to be possible.

All the results shown here are based on original proofs using analytic
combinatorics \cite{AnalComb2009}. The general strategy of analytic
combinatorics is to (i) describe simple combinatorial objects by a
generating function (ii) use transfer theorems to find the generating
function of complex structures based on these objects and (iii) analyze
the singularities of the resulting function to derive asymptotic
estimates. This method is sometimes considered counter-intuitive because
generating functions do not directly appeal to intuition
\cite{AnalComb1996}, but it allows to derive precise estimates with simple
proofs.

Since I expect most readers to not be familiar with analytic
combinatorics, I have tried to introduce the ideas progressively, hoping
that the logic of each step will be apparent. This also means that the
information is somewhat spread throughout the manuscript and does not
clearly separate the biological and the mathematical concepts. I have also
tried to use standard notations from analytic combinatorics for the proofs
of the claims, and standard notations from genomic for the specific
applications, which may be slightly confusing.  The key findings are
applications of recent results of Pemantle and Wilson on multivariate
asymptotics. The reader is referred to the original literature for the
proofs of those theorems \cite{PemWil08,AnalComb2013}.

\textbf{Related work:} Schbath and collaborators \cite{pmid10890387}
studied the effect of varying read length on the distribution of contigs.
Wendl \cite{pmid16901236} developed a theory taking into account ``edge
effects'' appearing when the read length is not negligible compared to the
size of the target genome. Stanhope \cite{pmid20686599} studied the
distribution of the largest contig using models of occupancy.


\section{Results}

\subsection{A combinatorial approach to the assembly problem}

We will formalize the assembly problem...

This situation corresponds to the assembly of a repeatless genome with a
single circular chromosome of size $G$. In this setup, the $n$ reads are
assumed to have the same length $L$, to be sequenced without error  and to
be uniformly distributed on the genome.

The assembly is completely determined by the $n$ distances between the
starts of consecutive reads. We need to compute the number of possible
configurations, and in how many of those the distance between consecutive
reads never exceeds a given threshold $k$. To do this, we will use
bivariate generating functions. This may look like an unintuitive approach
at first, but it will allow us to derive simpler proofs of the main
results.

If $(q_{k,n})_{k \geq 0, n \geq 0}$ is a bivariate array, the generating
function of the array is by definition

\begin{equation}
Q(x,y) = \sum_{k=0}^\infty \sum_{n=0}^\infty q_{k,n}x^ky^n.
\end{equation}

When $q_{k,n}$ counts a number of objects, we will say that $Q(x,y)$ is
the generating function of those objects. We will refer to $q_{k,n}$ as
the ``coefficient of $x^ky^n$ in $Q(x,y)$'', and also denote it as
$[x^ky^n] Q(x,y)$. The function $F$ and the bivariate sequence
$(q_{k,n})_{k \geq 0, n \geq 0}$ carry the same information, but some
combinatorial operations are easier to perform with Q, as we will
illustrate shortly.

We define an `interval' as the distance between the left ends of two
consecutive reads. Every interval has a size, which is a strictly positive
integer, and a weight equal to 1 and that will later be used to count
intervals.  There is exactly one interval of size $k$ and weight 1, and
zero in all other cases, so the generating function of intervals is

\begin{equation*}
I(x,y) = xy + x^2y + x^3y + \ldots
= xy\sum_{k=0}^\infty x^k = \frac{xy}{1-x}.
\end{equation*}

Operations on generating functions allow us to create more complex
combinatorial objects through transfer theorems.  We have already used
additions, which corresponds to disjoint unions. For instance, the
generating function above says that an interval is either an interval of
size 1 and weight 1, or an interval of size 2 and weight 1 \textit{etc}.
More generally, if $A(x,y)$ and $B(x,y)$ are the generating functions of
objects in disjoint sets $\mathcal{A}$ and $\mathcal{B}$, then
$A(x,y)+B(x,y)$ is the generating function of objects in $\mathcal{A} \cup
\mathcal{B}$.

Multiplications correspond to Cartesian products. More specifically, if
$A(x,y)$ and $B(x,y)$ are the generating functions of objects in sets
$\mathcal{A}$ and $\mathcal{B}$ (disjoint or not), and the size and weight
of a pair are the sums of individual sizes and weights, then
$A(x,y)B(x,y)$ is the generating function of objects in $\mathcal{A}
\times \mathcal{B}$. To prove this, observe that the pairs of size $k$ and
weight $n$ are made of all pairwise combinations of objects whose sizes
sum to $k$ and weights sum to $n$. The number of such pairs is
$\sum_{l=0}^k \sum_{m=0}^n a_{l,m}b_{k-l,n-m}$ so the generating function
of objects in $\mathcal{A} \times \mathcal{B}$ is


\begin{gather*}
\sum_{k=0}^\infty \sum_{n=0}^\infty \left( \sum_{l=0}^k \sum_{m=0}^n
  a_{m,l}b_{k-l,n-m}\right) x^k y^l = \\ 
\sum_{l=0}^\infty \sum_{m=0}^\infty \sum_{k=l}^\infty \sum_{n=m}^\infty
  a_{m,l}b_{k-l,n-m}x^{m + k-m} y^{l + n-l} = \\
\sum_{l=0}^\infty \sum_{m=0}^\infty a_{m,l} x^m y^l
  \sum_{k=l}^\infty \sum_{n=m}^\infty
  b_{k-l,n-m}x^{k-m} y^{n-l} = \\
B(x,y) \sum_{l=0}^\infty \sum_{m=0}^\infty a_{m,l} x^m y^l
 = A(x,y)B(x,y).
\end{gather*}

For instance, we can take $\mathcal{A}$ and $\mathcal{B}$ as the set of
intervals. If we define the size of a pair of intervals as the sum of
their sizes (by placing the ends next to each other) and its weight as 2,
then size and weight are additive. In these conditions, the generating
function of pairs of intervals is $I(x,y)^2$.

Applying the formula above multiple times, we see that if $A(x,y)$ is the
generating function of objects in $\mathcal{A}$, then $A(x,y)^n$ is the
generating function of objects in $\mathcal{A}^n$ (representing $n$-tuples
of objects in $\mathcal{A}$). Since joining $n$ consecutive intervals
gives a new interval whose size is the sum of individual sizes and whose
weight is the number of (atomic) intervals, $I(x,y)^n$ is the generating
function of the concatenation of $n$ intervals. It follows that the
generating function of all concatenations of intervals is

\begin{equation}
\label{eq:config}
C(x,y) = I(x,y)^0 + I(x,y)^1 +\ldots
= \sum_{n=0}^\infty \left( \frac{xy}{1-x} \right)^n
= \frac{1-x}{1 - x - xy}.
\end{equation}


The coefficient of $x^ky^n$ in $C(x,y)$ is the number of concatenations of
intervals of total size $k$ and total weight $n$, \textit{i.e.} the number
of ways to arrange $n+1$ reads such that the extreme left ends are
separated by $k$ nucleotides. It is thus interesting to extract this
coefficient from the generating function. The intermediate representation
in formula (\ref{eq:config}) shows that $[x^ky^n]C(x,y) = [x^k]
x^n/(1-x)^n$. To compute it, we derive $n-1$ times the equality $1/(1-x) =
1 + x + x^2 + \ldots$ to obtain

\begin{equation*}
(n-1)! \left( \frac{1}{1-x} \right)^n =
\sum_{k=n-1}^\infty k \cdot (k-1) \ldots (k-n+2) x^{k-n+1}.
\end{equation*}

Mutiplying through by $x^n/(n-1)!$ and rearranging the terms, we obtain

\begin{gather}
\notag
\left( \frac{x}{1-x} \right)^n =
\sum_{k=n}^\infty \frac{(k-1) \ldots (k-n+2)}{(n-1)!} x^k
= \sum_{k=n}^\infty {k-1 \choose n-1} x^k \text{, \textit{i.e.}} \\
\label{eq:C}
[x^ky^n]C(x,y) = {k-1 \choose n-1}.
\end{gather}

Equation (\ref{eq:C}) expresses the number of ways to arrange $n+1$ reads
such that the extreme left ends are separated by $k$ nucleotides. The main
question of the assembly problem is to determine how many of those consist
exclusively of $d$-intervals. If this represents a small fraction, chances
are that gaps will be present and that the assembly will be impossible.
Following the same rationale as above, we find the generating function of
concatenations of $d$-intervals to be

In addition, we define intervals of size no greater than $d$ as
``$d$-intervals''. Since the case $d=1$ is trivial, we will assume $d > 1$
throughout the manuscript. Following the same rationale as bove, we find
the generating function of $d$-intervals to be

\begin{equation}
\label{eq:dintervals}
I_d(x,y) = (x+x^2+\ldots+x^d)y.
\end{equation}

\begin{equation}
\label{eq:dinter}
C_d(x,y) = \sum_{n=0}^\infty \left(y(x+x^2+\ldots+x^d)\right)^n =
\frac{1}{1-y(x+x^2+\ldots+x^d)}.
\end{equation}

The coefficients of $x^ky^n$ in $C_d(x,y)$ are known as the polynomial
coefficients. Unforunately, they cannot be computed via a simple
expression, so we will need to use an asymptotic approximation.

\subsection{Asymptotic approximations}

Formulas (\ref{eq:config}) and (\ref{eq:dinter}) are the generating
functions of so called Riordan arrays, \textit{i.e.} bivariate sequences
$(a_{k,n})_{k,n}$ such that

\begin{equation*}
\sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n} x^k y^n =
\frac{\phi(x)}{1-y \nu(x)}.
\end{equation*}

Finding simple asymptotic estimates of bivariate sequences is usually not
easy, but for Riordan arrays, such results are available.

\begin{proposition}
\label{th:PW}
Assume that $F(x,y)$ is the generating function of a Riordan array, that
$k$ and $n$ tend to infinity and that $\lim k/n = \lambda$, then

\begin{equation}
\label{eq:Cd}
[x^ky^n]F(x,y) \sim \frac{\nu(x_\lambda)^n\phi(x_\lambda)}
  {x_\lambda^k\sqrt{2\pi n \sigma(x_\lambda)^2}},
\end{equation}

\noindent
where $x_\lambda$ is the solution of
$\mu(x) = x\nu'(x)/\nu(x) = \lambda$ and $\sigma(x)^2 = x \mu'(x)$.
\end{proposition}

The proof of this theorem was given by Pemantle and Wilson
\cite{PemWil08}. Here we will derive the concrete solution for $C_d$,
where $\phi(x) = 1$ and $\nu(x) = x + x^2 + \ldots +x^d$. The first task
is to find the solution of $\mu(x) = \lambda$.

\begin{proposition}
\label{th:mu}
The equation $\mu(x) = x\nu'(x)/\nu(x) = \lambda$ has a single solution
$x_\lambda$ for $1 \leq \lambda \leq d$.
\end{proposition}

\begin{proof}
We first demonstrate that for $x \geq 0$, $\mu$ is strictly increasing.

\begin{equation}
\label{eq:mu}
\mu(x) = x\frac{\nu'(x)}{\nu(x)} =
\frac{x+2x^2+3x^3+\ldots+dx^d}{x+x^2+\ldots+x^d} =
d+\frac{1}{1-x} - \frac{d}{1-x^d}.
\end{equation} 

Differentiating the last expression we obtain

\begin{equation}
\label{eq:muprime}
\mu'(x) = \frac{1}{(1-x)^2} -\frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{equation}

The function $f(\alpha) = x^{\alpha} = e^{\alpha \log(x)}$ is strictly
convex for every $x > 0$ and $x \neq 1$. Applying the definition of
convexity, we obtain the inequality

\begin{eqnarray*}
\frac{f(0)+\ldots+f(d-1)}{d} &>&
f\left(\frac{0+1+2+\ldots+d-1}{d}\right) \\
\frac{1+x+\ldots+x^{d-1}}{d} &>& f\left(\frac{d-1}{2}\right)
= x^{(d-1)/2} \\
\frac{1-x^d}{1-x} &>& dx^{(d-1)/2} \\
\frac{1}{(1-x)^2} &>& \frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{eqnarray*}

Combined with equation (\ref{eq:muprime}), the last inequality shows that
$\mu'(x) > 0$ for $x > 0$ and $x \neq 1$. Since $\mu'(0) = 1$ and $\mu'(1)
= (d+1)(d-1)/12$, $\mu$ is strictly increasing. Observing that $\mu(0) =
1$ and $\lim_{x\rightarrow\infty} \mu(x) = d$, the equation $\mu(x) =
\lambda$ has a unique solution provided $1 \leq \lambda \leq d$.
\end{proof}

\begin{remark}
The cases $\lambda > d$ and $\lambda < 1$ correspond to limits where $k >
nd$ and $k < n$, respectively. Since the size of a collection of $n$
$d$-intervals is between $n$ and $nd$, we have the trivial asymptotic
behavior $a_{k,n} = 0$ in both cases.
\end{remark}


The value of $x_\lambda$ can be found numerically. Once it is available,
we can compute $\nu(x_\lambda)$ and $\sigma(x_\lambda^2)$ from their
definitions, but numeric precision can become an issue if $n$ or $d$ is
very large. To avoid this, we use the equivalent forms


\begin{gather}
\label{eq:nu} %% Equation for nu.
\nu(x_\lambda) = \frac{dx_\lambda}{1+(d-\lambda)(1-x_\lambda)}, \\
\label{eq:sigma} %% Equation for sigma2.
\sigma(x_\lambda)^2 = \lambda(d-\lambda) -
  \frac{d-2\lambda+1}{1-x_\lambda}.
\end{gather}


\begin{example}

Let us consider the same problem as above, with a genome of size 25,000
and 10,001 reads. We assume that the reads are drawn uniformly at random
without replacement.

As above, $k=25000$, $n=10000$, $d=25$ and $\lambda = 2.5$. We solve
equation equation (\ref{eq:mustar}) by applying the Newton-Raphson method
to equation (\ref{eq:mu}) with $\lambda-1$ and $d-1$ and obtain
$x_\lambda \approx 0.60001177$. Using equations (\ref{eq:nustar}) and
(\ref{eq:sigmastar}) we obtain $\nu_*(x_\lambda) \approx 1.50006684$ and
$\sigma(x_\lambda)^2 \approx 3.747554$. We compute equation
(\ref{eq:Cd}) in logarithmic space and obtain

\begin{eqnarray*}
\log(a_{k,n}) &\approx& 10000\log(1.50006684) - 25000\log(0.60001177) \\
&-& \log(10000)/2 - \log(3.747554)/2 - \log(2\pi)/2
\approx 16819.0783
\end{eqnarray*}

This is to be compared to the total number of configurations in
logarithmic space, which according to equation (\ref{eq:Cstar}) is

\begin{equation*}
\log { 24999 \choose 9999 } \approx 16819.1067
\end{equation*}

The estimated probability that a configuration corresponds to a coverage
by $25$-intervals is
thus

\begin{equation*}
\exp(16819.0783-16819.1067) \approx 0.972.
\end{equation*}

Random simulations with 10,000 samples gave an estimate for this
probability equal to $0.973$, again very close to the numerical
approximation. In this example, $x_\lambda$ and $\nu_*(x_\lambda)$ must be
approximated to eight digits to obtain an approximate accute to within
1\%. On real problems, $n$ and $k$ can be several orders of magnitude
higher, which shows the importance of using numerically accurate formulas.

\end{example}

It is possible to remove duplicate reads, but it would be useful to know
upfront how many unique reads we expect. If there are $k+1$ possible
locations and $n+1$ reads, each position is sampled on average
$(n+1)/(k+1)$ times. Using the Poisson approximation, the probability that
a position is not sampled is $e^{-(n+1)/(k+1)}$ so that the frequency of
sampled positions is $1-e^{-(n+1)/(k+1)}$.


\begin{example}

Once again we consider a problem with a genome of size 25,000 and 10,001
reads. We assume that the reads are drawn uniformly at random with
replacement.

As above, $k=25000$ and $d=25$, but we need to replace $n=10000$ by the
estimated number of unique reads $n_* = 25000 \cdot e^{-10001/25001} =
8241.999 \approx 8242$. This give a value for $\lambda$ approximately
equal to 3.033. We follow the same calculations as in the previous example
and we obtain $x_\lambda \approx 0.67044393$, $\nu_*(x_\lambda) \approx
2.03429224$ and $\sigma_*(x_\lambda)^2 \approx 6.144598$.

\begin{eqnarray*}
\log(a_{k,n}) &\approx& 8242\log(2.03429224) - 25000\log(0.67044393) \\
&-& \log(8242)/2 - \log(6.144598)/2 - \log(2\pi)/2
\approx 15842.084.
\end{eqnarray*}

The total number of configurations in logarithmic space is again
obtained from equation (\ref{eq:Cstar}) as

\begin{equation*}
\log { 24999 \choose 8241 } \approx 15842.457.
\end{equation*}

Finally, the estimated probability that a configuration corresponds to a
coverage by $25$-intervals is

\begin{equation*}
\exp(15842.084-15842.457) \approx 0.689.
\end{equation*}

For comparison, random simulations with 10,000 samples gave an estimate
for this probability equal to $0.688$.

\end{example}

In summary, the asymptotic estimates are accurate in the range where they
are useful, namely when the probability of covering the genome is not
exceedingly close to 0 or to 1.

\subsection{The average number of contigs}

We now introduce $d$-gaps as intervals of size greater than $d$. The same
way as $y$ was used to count $d$-intervals, we introduce $z$ to count
$d$-gaps. So the generating function of $d$-gaps is

\begin{equation}
\label{eq:dgaps}
G_d(x,z) = yz(x^{d+1}+x^{d+2}+\ldots) = yz\frac{x^{d+1}}{1-x}.
\end{equation}

We define a $d$-assembly as a concatenation of $d$-intervals and $d$-gaps.
Each link of a $d$-assembly is either a $d$-interval or a $d$-gap so the
generating function of links is the sum of (\ref{eq:dintervals}) and
(\ref{eq:dgaps}). Since a $d$-assembly is a sequence of links, the
generating function is

\begin{equation*}
A_d(x,y,z) = \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
yz\frac{x^{d+1}}{1-x}\right)^n =
\frac{1-x}{1-x-y\left(x(1-x^d) +zx^{d+1}\right)}.
\end{equation*}

$A_d(x,y,z)$ is the generating function of a three-dimensional array
$(a_{k,n,m})$, where each term is the number of $d$-assemblies of size $k$
with $n$ $d$-intervals and $m$ $d$-gaps. The average number of $d$-gaps
for a given value $k$ and $n$ is the total number of $d$-gaps in
$d$-assemblies of size $k$ with $n$ $d$-intervals, divided by the number
of such assemblies. In other words the average is

\begin{equation}
\label{eq:average}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m}.
\end{equation}

To compute this number, observe that

\begin{equation*}
A_d(x,y,1) = \sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty a_{k,n,m}\right) x^ky^n.
\end{equation*}

So the denominator of (\ref{eq:average}) is the general term of the
bivariate generating function

\begin{equation*}
A(x,y) = \frac{1-x}{1-x-xy} = \frac{1}{1-yx/(1-x)}.
\end{equation*}

This is equation (\ref{eq:config}). Even though we could exact the
coefficients from this generating function, we can obtain a simpler
approximation of (\ref{eq:average}) as we will show now.  To compute the
numerator of (\ref{eq:average}), we differentiate $A_d(x,y,z)$ with
respect to $z$ and we observe that

\begin{equation*}
\partial A_d(x,y,z)/\partial z\Bigr|_{\substack{\\z=1}} =
\sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty ma_{k,n,m}\right) x^ky^n.
\end{equation*}

So the numerator of (\ref{eq:average}) is the general term of the
bivariate generating function

\begin{equation*}
\frac{yx^{d+1}(1-x)}{\left(1-x-xy\right)^2}.
\end{equation*}

This is not the generating function of a Riordan array, but observe that
it is equal to $y\partial D(x,y)/\partial y$, where

\begin{equation*}
D(x,y) = \frac{x^d(1-x)}{1-x-xy} =
\frac{x^d}{1-yx(1-x)}.
\end{equation*}

$D(x,y)$ is the generating function of a Riordan array, for which we can
obtain accurate coefficients asymptotics. Since $[x^ky^n]y\partial D(x,y)
/ \partial y = n[x^ky^n]D(x,y)$, we can also obtain accurate
asymptotics for the numerator of (\ref{eq:average}).

We also note that the function $\nu$ is the same for $A(x,y)$ and
$D(x,y)$, so according to proposition \ref{th:PW}, the values of
$x_\lambda$, $\nu(x_\lambda)$ and $\sigma(x_\lambda)^2$ are the same in
both cases. This implies that

\begin{equation*}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m} \sim
n x_\lambda^d.
\end{equation*}

$\mu = 1/(1-x)$. Solution gives $x = 1-1/\lambda$, so the average is
directly $n((\lambda-1)/\lambda$. The final solution is

\begin{equation*}
n\left(1-n/k\right)^d.
\end{equation*}

\begin{example}
Consider a genome of size 25,000 and 5,001 reads. Here $k = $ and $n =
5000$ (so $\lambda = 5$) and $d = 25$. We obtain $x_\lambda = 0.8$
and $n x_\lambda^d \approx 18.89$. The simulations give
$18.85$. In comparison, the Lander-Waterman estimate is $ne^{-nd/k} =
33.69$.
\end{example}

%---------------------------------------------------------------
%	REFERENCE LIST
%---------------------------------------------------------------

\bibliography{pubmed,extra}
\bibliographystyle{plain}

%----------------------------------------------------------------

\end{document}
