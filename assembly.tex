\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cite}

\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem*{remark}{Remark}

%---------------------------------------------------------------

\title{The expected number of contigs}
\author{
\textsc{Guillaume Filion} \\ [1ex]
\normalsize CRG, Barcelona
}
\date{\today}

%---------------------------------------------------------------
%---------------------------------------------------------------


\begin{document}

\maketitle

\begin{abstract}
Here is the text of the abstract. I need to type more in order to see if
this goes beyond the two columns of the text.
\end{abstract}


%---------------------------------------------------------------
%---------------------------------------------------------------

\section{Introduction}

How many reads should I sequence? How long should they be? With what
minimum overlap? These questions were first addressed in this context by
Lander and Waterman in a landmark study that defined the ``classic
theory'' of assembly \cite{pmid3294162}, giving estimates of the number of
contigs. At the time, genome assembly was a long term endeavour and it
made sense to gather information about the progress of the project. The
Lander-Waterman estimators are thus accurate for intermediate stages where
the number of contigs is high, but their quality drops when the assembly
nears completion.

Nowadays, genome assembly is several orders of magnitude faster. The
questions remain the same, but in many cases the assembly does not have a
proper intermediate stage because the sequencing capacity of a single run
is potentially sufficient to assemble the target genome. It is thus
desirable to minimize the amount of resources that a necessary for the
task, and estimators that are accurate when assembly is likely to be
possible are generally more useful. Likewise, the parameters of the
algorithm must minimize the risk of misassembly while giving the highest
chance that assembly will be possible. This can be done efficiently only
if the statistical properties of the assembly are also understood when it
is likely to be possible.

These are asymptotic estimates, which means that unlike the classical
estimators, they get more accurate when the number of reads increases. In
practice, they are accurate to within 1\% even for a few hundred reads
taken from a genome of a few hunder nucleotides.

All the results shown here are based on original proofs using analytic
combinatorics \cite{AnalComb2009}. The general strategy of analytic
combinatorics is to (i) describe simple combinatorial objects by a
generating function (ii) use simple mathematical operations to find the
generating function of complex structures based on these objects and (iii)
analyze the singularities of the resulting function to derive asymptotic
estimates. This method is sometimes considered counter-intuitive because
generating functions do not directly appeal to intuition
\cite{AnalComb1996}, but it allows to derive precise estimates with simple
proofs.

Since I expect most readers to not be familiar with analytic
combinatorics, I have tried to introduce the ideas progressively, hoping
that the logic of each step will be apparent. This also means that the
information is somewhat spread throughout the manuscript and does not
clearly separate the biological and the mathematical concepts. I have also
tried to use standard notations from analytic combinatorics for the proofs
of the claims, and standard notations from genomic for the specific
applications, which may be slightly confusing.  The key findings are
applications of recent results of Pemantle and Wilson on multivariate
asymptotics. The reader is referred to the original literature for the
proofs of those theorems \cite{PemWil08,AnalComb2013}.

\textbf{Related work:} Schbath and collaborators \cite{pmid10890387}
studied the effect of varying read length on the distribution of contigs.
Wendl \cite{pmid16901236} developed a theory taking into account ``edge
effects'' appearing when the read length is not negligible compared to the
size of the target genome. Stanhope \cite{pmid20686599} studied the
distribution of the largest contig using models of occupancy.


\section{Results}

\subsection{Analytic combinatorics of the assembly problem}

If $(a_{k,n})_{k \geq 0, n \geq 0}$ is a bivariate array, the generating
function of the array is by definition

\begin{equation*}
F(x,y) = \sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n}x^ky^n.
\end{equation*}

When $a_{k,n}$ counts the number of objects in a set $\mathcal{A}$, we
will say that $F(x,y)$ is the generating function of those objects. When
the emphasis is on the generating function, will refer to $a_{k,n}$ as the
``coefficient of $x^ky^n$ in $F(x,y)$'', and denote it as ``$[x^ky^n]
F(x,y)$'' when convenient. The function $F$ and the bivariate sequence
$(a_{k,n})_{k \geq 0, n \geq 0}$ carry the same information, but some
combinatorial operations are easier to perform with $F$, as we will see
below.

The first combinatorial object that we will consider is the ``interval'',
defined here as the distance between the left ends of two consecutive
reads. We will call this distance the \emph{size} of the interval, and we
will impose it to be a strictly positive integer. This means that two
reads cannot map to the same location, but we will later see how to relax
this constraint. We will also give each interval a \emph{weight} equal to
$1$. This may seem odd, but it will allow us to count intervals when we
create more complex objects.

\begin{remark}
In the fields of combinatorics, the coverage of $k$ nucleotides by $n$
intervals corresponds to a composition, \textit{i.e.} the break-down of
$k$ as a sum of $n$ positive integers \cite{AnalComb2009}. All the results
presented in this article can be interpreted more widely as properties of
compositions.
\end{remark}

We will use analytic combinatoric to derive asymptotic estimates in a
context where the results will be familiar. For this, we need to obtain
the generating function of intervals. There is exactly one interval of
size $k$ and weight 1 ($k > 0$), and zero interval in all other cases, so
$a_{k,n} = 1$ if $n = 1$ and $k > 0$, and $a_{k,n} = 0$ otherwise. The
generating function of intervals is thus

\begin{equation}
\label{eq:F}
F(x,y) = xy + x^2y + x^3y + \ldots
= xy(1+x+x^2+\ldots) = \frac{xy}{1-x}.
\end{equation}

In this expression, we say that $x$ ``marks'' the size and that $y$
``marks'' the weight.

Operations on generating functions allow us to create more complex
combinatorial objects through mathematical operations.  We have already
used additions, which corresponds to disjoint unions. For instance, the
generating function above says that an interval is either an interval of
size 1 and weight 1, or an interval of size 2 and weight 1, or an interval
of size 3 and weight 1 \textit{etc}. More generally, if $Q(x,y)$ and
$R(x,y)$ are the generating functions of objects in disjoint sets
$\mathcal{Q}$ and $\mathcal{R}$, then $Q(x,y)+R(x,y)$ is the generating
function of objects in $\mathcal{Q} \cup \mathcal{R}$.

Multiplications correspond to Cartesian products. More specifically, if
$Q(x,y)$ and $R(x,y)$ are the generating functions of objects in sets
$\mathcal{Q}$ and $\mathcal{R}$ (disjoint or not), then $Q(x,y)R(x,y)$ is
the generating function of objects in $\mathcal{Q} \times \mathcal{R}$,
provided the attributes are \emph{additive}. For instance, we can take
both $\mathcal{Q}$ and $\mathcal{R}$ as the set of intervals. If we define
the size of a pair of intervals as the sum of their sizes (by placing the
ends next to each other) and its weight as 2, then size and weight are
additive, so the generating function of pairs of intervals is $Q(x,y)^2$.

To see this, observe that the pairs of intervals of size $k$ and weight
$n$ are made of all pairwise combinations of intervals whose sizes sum to
$k$ and weights sum to $n$. The number of such pairs is $\sum_{l=0}^k
\sum_{m=0}^n q_{l,m}q_{k-l,n-m}$ so the generating function is

\begin{equation*}
\begin{split}
\sum_{k=0}^\infty &\sum_{n=0}^\infty \left( \sum_{l=0}^k \sum_{m=0}^n
  q_{l,m}q_{k-l,n-m}\right) x^k y^n \\
&= \sum_{l=0}^\infty \sum_{m=0}^\infty \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{l,m}q_{k-l,n-m}x^{l + k-l} y^{m + n-m} \\ 
&= \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
  \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{k-l,n-m}x^{k-l} y^{n-m} \\
&= Q(x,y) \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
 = Q(x,y)Q(x,y).
\end{split}
\end{equation*}


Applying the formula above multiple times, we see that if $A(x,y)$ is the
generating function of objects in $\mathcal{A}$, then $A(x,y)^n$ is the
generating function of objects in $\mathcal{A}^n$ (representing $n$-tuples
of objects in $\mathcal{A}$). Since joining $n$ consecutive intervals
gives a new interval whose size is the sum of individual sizes and whose
weight is the number of (atomic) intervals, $I(x,y)^n$ is the generating
function of the concatenation of $n$ intervals. It follows that the
generating function of all joined intervals is

\begin{equation}
\begin{split}
\label{eq:C}
C(x,y) &= \sum_{n=0}^\infty \left( \frac{xy}{1-x} \right)^n
= \frac{1}{1 - xy/(1-x)} \\
&= \frac{1-x}{1-x(1+y)} = (1-x) \sum_{k=0}^\infty \left(x(1+y) \right)^k.
\end{split}
\end{equation}

Using Newton's binomial formula, we can easily obtain an explicit
expression for the coefficients of $C(x,y)$, namely

\begin{equation*}
C(x,y) = (1-x)\sum_{k=0}^\infty x^k\sum_{n=0}^k {k \choose n} y^n
= \sum_{k=0}^\infty\sum_{n=0}^\infty{k \choose n} (x^ky^n - x^{k+1}y^n).
\end{equation*}

It follows that

\begin{equation}
\label{eq:coefC}
[x^ky^n] C(x,y) =
{k \choose n} - {k-1 \choose n} = {k-1 \choose n-1}
\text{, provided $k > 0$, $n > 0$}.
\end{equation}

In the cases not covered by formula (\ref{eq:coefC}), the coefficients are
equal to 0, except for $k = n = 0$ where the coefficient is equal to 1.

\begin{remark}
The last expression in (\ref{eq:C}) gives an alternative construction for
sequences of intervals. The term $1+y$ is the generating function of bits,
\textit{i.e.} elements of $\{0,1\}$, so $(x(1+y))^k$ is the generating
function of bit strings where $x$ marks the size. Sequences of intervals
are equivalent to bit strings, because we can encode left end of intervals
with a $1$ and every other position with a $0$.
\end{remark}

In this example, we were able to obtain an explicit expression for the
number of ways that $n$ intervals can cover $k$ nucleotides. We could use
Stirling's formula to obtain the asymptotic behavior of those
coefficients, but in general this information is directly available from
the generating function, especially when it has a simple form such as
(\ref{eq:C}).

Riordan arrays are bivariate arrays $(a_{k,n})_{k,n}$ such that the
generating function satisfies

\begin{equation*}
\sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n} x^k y^n =
\frac{\phi(x)}{1-y \nu(x)}.
\end{equation*}

\begin{proposition}
\label{th:PW}
Assume that $F(x,y)$ is the generating function of a Riordan array, and
that $k$ and $n$ tend to infinity with $\lim k/n = \lambda$, then

\begin{equation}
\label{eq:assRA}
[x^ky^n]F(x,y) \sim \frac{\nu(x_\lambda)^n\phi(x_\lambda)}
  {x_\lambda^k\sqrt{2\pi n \sigma(x_\lambda)^2}},
\end{equation}

\noindent
where $x_\lambda$ is the solution of $\mu(x) = x\nu'(x)/\nu(x) = \lambda$
and where $\sigma(x)^2 = x \mu'(x)$.
\end{proposition}

In essence, proposition \ref{th:PW} says that if $k \sim \lambda n$ and if
we can find the solution of the equation $\mu(x) = \lambda$, then we get
the asymptotic growth of the Riordan array $a_{k,n}$. The proof of this
theorem is outside the scope of this article, the interested reader is
referred to the original results of Pemantle and Wilson
\cite{PemWil08,AnalComb2013}.

Expression (\ref{eq:C}) shows that $C(x,y)$ is the generating function of
a Riordan array with $\phi(x) = 1$ and $\nu(x) = x/(1-x)$.  Here $\mu(x) =
1/(1-x)$ and $\sigma^2(x) = x/(1-x)^2$, so we obtain $x_\lambda = (\lambda
-1)/\lambda$, $\nu(x_\lambda) = \lambda -1$, and $\sigma^2(x_\lambda) =
\lambda(\lambda-1)$. Combining this with $\lambda \sim k/n$ we obtain

\begin{equation}
\label{eq:assBC}
{k-1 \choose n-1} \sim \frac{k^{k-1}}{n^{n-1}(k-n)^{k-n}}
\sqrt{\frac{k}{2\pi n(k-n)}}.
\end{equation}

This section illustrates the strategy of analytic combinatorics: we
specify combinatorial structures through generating functions, and we use
general theorems to extract coefficient asymptotics. This approach may
seem counter-intuitive or overly complex, but we will see in the next
sections how it can lead to results that are otherwise not available. 

\subsection{Successful assembly}

In the shotgun strategy of genome assembly, reads are merged if they
overlap by some minimum amount of nucleotides. The process continues with
consecutive reads in both directions, as long as they overlap by this
minimum amount of nucleotides. The merged sequences are called
\emph{contigs}, and the assembly of a chromosome is theoretically possible
if it consists of a single contig (in practice, the fact that biological
sequences are interspersed with repeats makes assembly more difficult). It
is thus interesting to determine the \textit{a priori} probability of this
event.

From here on, $d$ will denote the maximal allowed distance between the
left ends of consecutive reads that can be merged. Note that the minimum
amount of nucleotides that reads must overlp is $L-d$, where $L$ is their
length. We also introduce intervals of size no greater than $d$ and call
them ``$d$-intervals''. Since the case $d=1$ is trivial, we will assume $d
> 1$ throughout.

Following the same rationale as bove, we first need to find the generating
function of $d$-intervals. This is done easily by stopping the sum in
(\ref{eq:F}) after $x^dy$, so we obtain $F_d(x,y) = (x+x^2+\ldots+x^d)y$.
Since a contig is a sequence of $d$-intervals, the generating function of
contigs is

\begin{equation}
\label{eq:Cd}
C_d(x,y) = \sum_{n=0}^\infty \left(y(x+x^2+\ldots+x^d)\right)^n =
\frac{1}{1-y(x+x^2+\ldots+x^d)}.
\end{equation}

The coefficients of $C_d(x,y)$ are known as the polynomial coefficients,
but they cannot be expressed in closed form. However, this is not an issue
because (\ref{eq:Cd}) is the generating function of a Riordan with
$\phi(x) = 1$ and $\nu(x) = x + x^2 + \ldots + x^d$, so we can extract
their asymptotic behavior from proposition \ref{th:PW}.

\begin{lemma}
\label{th:mu}
For $\nu(x) = x+x^2+\ldots+x^d$, the equation $\mu(x) = x\nu'(x)/\nu(x) =
\lambda$ has a single solution $x_\lambda$ for $1 \leq \lambda \leq d$.
\end{lemma}

\begin{proof}
We first demonstrate that for $x \geq 0$, $\mu$ is strictly increasing.
This will ensure that if the solution is unique if it exists.

\begin{equation}
\label{eq:mu}
\mu(x) = x\frac{\nu'(x)}{\nu(x)} =
\frac{x+2x^2+3x^3+\ldots+dx^d}{x+x^2+\ldots+x^d} =
d+\frac{1}{1-x} - \frac{d}{1-x^d}.
\end{equation} 

Differentiating the last expression we obtain

\begin{equation}
\label{eq:muprime}
\mu'(x) = \frac{1}{(1-x)^2} -\frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{equation}

The function $f(\alpha) = x^{\alpha} = e^{\alpha \log(x)}$ is strictly
convex for every $x > 0$ and $x \neq 1$. Applying the definition of
convexity, we obtain the inequality

\begin{eqnarray*}
\frac{f(0)+\ldots+f(d-1)}{d} &>&
f\left(\frac{0+1+2+\ldots+d-1}{d}\right) \\
\frac{1+x+\ldots+x^{d-1}}{d} &>& f\left(\frac{d-1}{2}\right)
= x^{(d-1)/2} \\
\frac{1-x^d}{1-x} &>& dx^{(d-1)/2} \\
\frac{1}{(1-x)^2} &>& \frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{eqnarray*}

Combined with equation (\ref{eq:muprime}), the last inequality shows that
$\mu'(x) > 0$ for $x > 0$ and $x \neq 1$. Since $\mu'(0) = 1$ and $\mu'(1)
= (d+1)(d-1)/12$, $\mu$ is strictly increasing (note that $\mu'(1)$ is
properly defined but that $\mu'(0)$ must be defined by continuity).
Observing that $\mu(0) = 1$ and $\lim_{x\rightarrow\infty} \mu(x) = d$,
the equation $\mu(x) = \lambda$ has a unique solution provided $1 \leq
\lambda \leq d$.
\end{proof}

\begin{remark}
The cases $\lambda > d$ and $\lambda < 1$ correspond to limits where $k >
nd$ and $k < n$, respectively. Since the size of a collection of $n$
$d$-intervals is between $n$ and $nd$, we have the trivial asymptotic
behavior $a_{k,n} = 0$ in both cases.
\end{remark}


The value of $x_\lambda$ can be found numerically using expression
(\ref{eq:mu}).  Once it is available, we can compute $\nu(x_\lambda)$ and
$\sigma(x_\lambda^2)$ from their definitions, but numeric precision can
become an issue if $n$ or $d$ is very large. To avoid this, we can use the
equivalent expressions


\begin{gather}
\label{eq:nu} %% Equation for nu.
\nu(x_\lambda) = \frac{dx_\lambda}{1+(d-\lambda)(1-x_\lambda)}, \\
\label{eq:sigma} %% Equation for sigma2.
\sigma(x_\lambda)^2 = \lambda(d-\lambda) -
  \frac{d-2\lambda+1}{1-x_\lambda}.
\end{gather}

The coefficients of $C(x,y)$ give the total number of configurations, and
those of $C_d(x,y)$ give the number of configurations with a single
contig. The probability that a chromosome can be assembled is thus
$[x^ky^n] C_d(x,y) / [x^ky^n] C(x,y)$, which can be approximated with the
asymptotic formulas developed above.

\begin{example}
Let us consider a genome of size 25,000. We assume that 10,001 reads are
drawn uniformly at random without replacement. This translates into
$k=25000$ and $n=10000$. Setting the maximum distance between reads in a
contig to $d=25$, what is the probability that the genome can be
assembled?

First, we get $\lambda = k/n = 2.5$. We then solve equation (\ref{eq:mu})
with the Newton-Raphson method and obtain $x_\lambda \approx 0.600011377$.
Using equations (\ref{eq:nu}) and (\ref{eq:sigma}) we obtain
$\nu(x_\lambda) \approx 1.50006684$ and $\sigma(x_\lambda)^2 \approx
3.747554$. We compute equation (\ref{eq:assRA}) in logarithmic space and
obtain

\begin{equation*}
\begin{split}
10000&\log(1.50006684) - 25000\log(0.600011377) \\
- &\log(10000)/2 - \log(3.747554)/2 - \log(2\pi)/2
\approx 16819.0786.
\end{split}
\end{equation*}

We also compute 

\begin{equation*}
\log { 24999 \choose 9999 } \approx 16819.1067.
\end{equation*}

The estimated probability that a configuration corresponds to a coverage
by $25$-intervals is thus

\begin{equation*}
\exp(16819.0783-16819.1067) \approx 0.972.
\end{equation*}

Randomly sampling 200,000 configurations gives an estimate for this
probability equal to $0.972$, close to the numerical approximation by
three digits. In this example, $x_\lambda$ and $\nu(x_\lambda)$ must be
approximated to eight digits in order to obtain an approximate accurate to
within 1\%. Using the definition of $\nu$ instead of (\ref{eq:nu}), we
would obtain an estimate equal to $0.983$. The difference is negligible
here, but on real problems, $n$ and $k$ can be several orders of magnitude
higher, which will increase the difference.
\end{example}

In the above, we have assumed that all the reads map to different
locations. It is possible to enforce this by removing duplicate reads, but
it would be more useful to estimate the probability that the chromosome
can be assembled before resources are spent. 

Each nucleotide of the chromosome corresponds to the left end of a read
$n/k$ times on average. Because $k$ and $n$ are both large, we can
approximate the number of time a nucleotide is drawn by a Poisson
distribution with mean $n/k$. The probability that a position is not
sampled is approximately $e^{-n/k}$ so that the frequency of sampled
positions is $1-e^{-n/k}$. The strategy is thus to replace the true number
of reads by the expected number of distinct reads

\begin{equation}
\label{eq:nstar}
n_* = k(1-e^{-n/k}).
\end{equation}


\begin{example}
We consider the same problem as in the previous example, with a genome of
size 25,000 and 10,001 reads at a maximum distance of 25 ncleotides, but
this time the reads are drawn uniformly at random with replacement. As
above, $k=25000$, but we need to replace $n$ by $n_* = 25000 \cdot
(1-e^{-10000/25000}) \approx 8241.9988$.

We now obtain $\lambda = k/n_* \approx 3.033$. Following the same
calculations as in the previous example, we obtain $x_\lambda \approx
0.67044394$, $\nu_*(x_\lambda) \approx 2.03429230$ and
$\sigma_*(x_\lambda)^2 \approx 6.144599$. Computing (\ref{eq:assRA}) in
logarithmic space with the new values yields

\begin{equation*}
\begin{split}
8241.9988\log(2.03429230) - &25000\log(0.67044394) \\
- \log(8241.9988)/2 - &\log(6.144599)/2 - \log(2\pi)/2
\approx 15842.084.
\end{split}
\end{equation*}

Likewise, we also have

\begin{equation*}
\log { 24999 \choose 8240.9988 } \approx 15842.457.
\end{equation*}

Finally, the estimated probability that a configuration corresponds to a
coverage by $25$-intervals is

\begin{equation*}
\exp(15842.084-15842.457) \approx 0.689.
\end{equation*}

Randomly sampling 200,000 configurations gives an estimate for this
probability equal to $0.688$. This is less accurate than in the previous
example, but still within 1\% of the real value.
\end{example}

In conclusion, we can continue to assume that reads are all distinct, and
use formula (\ref{eq:nstar}) whenever the assumption does not hold.

\begin{remark}
Allowing intervals and $d$-intervals to have size $0$ is not the proper
way to address this issue because it gives a different sampling scheme.
For $4$ reads covering $2$ nucleotides (\textit{i.e.} $k=1$ and $n=3$),
the probability that the first two intervals have size $0$ would be $1/3$,
whereas it should be $2/7$.
\end{remark}

In summary, estimates of the chances of success of the assembly are
accurate in the range where they are the most useful, namely when the
value is not exceedingly close to 0 or to 1. The steps required to
automate the estimation are recapitulated here:

\begin{enumerate}
\item Compute the expected number of distinct reads $n_*$ using
(\ref{eq:nstar}). 
\item Compute $\lambda = k/n_*$.
\item Solve $\mu(x_\lambda) = \lambda$ by the Newton-Raphson method using
(\ref{eq:mu}) and (\ref{eq:muprime}).
\item Compute $\nu(x_\lambda)$ and $\sigma^2(x_\lambda)$ using
(\ref{eq:nu}) and (\ref{eq:sigma}).
\item Compute (\ref{eq:assRA}) in logarithmic space.
\item Compute (\ref{eq:coefC}) in logarithmic space.
\item Take the difference of the last two terms and exponentiate.
\end{enumerate}

\subsection{The average number of contigs}
\label{sec:av}

We now introduce $d$-gaps as intervals of size greater than $d$. The same
way as we used $y$ to mark $d$-intervals, we will use $z$ to mark
$d$-gaps. In other words the generating function of $d$-gaps is

\begin{equation*}
G_d(x,z) = yz(x^{d+1}+x^{d+2}+\ldots) = yz\frac{x^{d+1}}{1-x}.
\end{equation*}

By joining $d$-intervals or $d$-gaps we obtain the configuration of an
assembly problem, with generating function

\begin{equation*}
\begin{split}
A(x,y,z) &= \sum_{n=0}^\infty \left(J_d(x,y) + G_d(x,z) \right) \\
&= \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
yz\frac{x^{d+1}}{1-x}\right)^n =
\frac{1-x}{1-x-y\left(x(1-x^d) +zx^{d+1}\right)}.
\end{split}
\end{equation*}

$A(x,y,z)$ is the generating function of a three-dimensional array
$(a_{k,n,m})$, where each term is the number of configurations of total
size $k$ with $n$ $d$-intervals and $m$ $d$-gaps. The average number of
$d$-gaps for a given value $k$ and $n$ is

\begin{equation}
\label{eq:average}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m}.
\end{equation}

To compute the generating function of the denomiator of
(\ref{eq:average}), observe that

\begin{equation*}
A(x,y,1) = \sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty a_{k,n,m}\right) x^ky^n.
\end{equation*}

So by setting $z$ to 1, we obtain the generating function of the
denominator of (\ref{eq:average}) as

\begin{equation*}
\frac{1-x}{1-x-xy} = \frac{1}{1-yx/(1-x)} = J(x,y).
\end{equation*}

Even though we know the coefficients of this generating function, we will
not need them to obtain a simple asymptotic approximation of
(\ref{eq:average}). To compute the numerator of (\ref{eq:average}), we
differentiate $A(x,y,z)$ with respect to $z$ and we observe that

\begin{equation*}
\frac{\partial A(x,y,z)}{\partial z}\Bigr|_{\substack{\\z=1}} =
\sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty ma_{k,n,m}\right) x^ky^n.
\end{equation*}

So by differentiating $A(x,y,z)$ and settig $z$ to 1, we obtain the
generating function of the numerator of (\ref{eq:average}) as

\begin{equation*}
\frac{yx^{d+1}(1-x)}{\left(1-x-xy\right)^2}.
\end{equation*}

This is not the generating function of a Riordan array, but observe that
it is equal to $y\partial D(x,y)/\partial y$, where

\begin{equation*}
D(x,y) = \frac{x^d(1-x)}{1-x-xy} =
\frac{x^d}{1-yx/(1-x)}.
\end{equation*}

$D(x,y)$ is the generating function of a Riordan array with $\phi(x) =
x^d$ and $\nu(x) = x/(1-x)$. We can obtain obtain accurate asymptotic
estimates of $[x^ky^n]D(x,y)$, and since $[x^ky^n]y\partial D(x,y) /
\partial y = n[x^ky^n]D(x,y)$, we can also obtain accurate asymptotics for
the numerator of (\ref{eq:average}).

We also note that the function $\nu$ is the same for $J(x,y)$ and
$D(x,y)$, so according to proposition \ref{th:PW}, the values of
$x_\lambda$, $\nu(x_\lambda)$ and $\sigma(x_\lambda)^2$ are the same in
both cases. This implies that

\begin{equation*}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m} \sim
n x_\lambda^d.
\end{equation*}

We have seen in the remark after proposition \ref{th:PW} that $x_\lambda =
(\lambda-1)/\lambda$, so the average number of gaps is $n(1-1/\lambda)^d$,
which we can express the general form

\begin{equation*}
n\left(1-n/k\right)^d.
\end{equation*}

\begin{example}
Consider a genome of size 25,000 and 5,001 reads. Here $k = $ and $n =
5000$ (so $\lambda = 5$) and $d = 25$. We obtain $x_\lambda = 0.8$
and $n x_\lambda^d \approx 18.89$. The simulations give
$18.85$. In comparison, the Lander-Waterman estimate is $ne^{-nd/k} =
33.69$.
\end{example}

\subsection{The average size of contigs}

In the section above, $z$ was used to mark gaps. Here we will use it to
mark their size, so the generating function of $d$-gaps will be defined as
$x^{d+1}z^{d+1} + x^{d+2}z^{d+2} + \ldots = x^{d+1}z^{d+1}/(1-xz)$.

\begin{equation*}
\tilde{A}_d(x,y,z) = \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
y\frac{x^{d+1}z^{d+1}}{1-xz}\right)^n =
\frac{1}{1-y \left(x\frac{1-x^d}{1-x} +
\frac{x^{d+1}z^{d+1}}{1-xz} \right)}.
\end{equation*}

\begin{equation*}
\frac{\partial\tilde{A}_d(x,y,z)}{\partial z}\Bigr|_{\substack{\\z=1}} =
\sum_{k=0}^\infty\sum_{n=0}^\infty
\end{equation*}


%---------------------------------------------------------------
%---------------------------------------------------------------

\bibliography{pubmed,extra}
\bibliographystyle{plain}

%----------------------------------------------------------------

\end{document}
