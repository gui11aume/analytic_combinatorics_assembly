\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cite}

\newtheorem{proposition}{Proposition}
\newtheorem*{remark}{Remark}
\newtheorem{example}{Example}

%---------------------------------------------------------------

\title{The expected number of contigs}
\author{
\textsc{Guillaume Filion} \\ [1ex]
\normalsize CRG, Barcelona
}
\date{\today}

%---------------------------------------------------------------
%---------------------------------------------------------------


\begin{document}

\maketitle

\begin{abstract}
Here is the text of the abstract. I need to type more in order to see if
this goes beyond the two columns of the text.
\end{abstract}


%---------------------------------------------------------------
%---------------------------------------------------------------

\section{Introduction}

How many reads should I sequence? How long should they be? With what
minimum overlap? These questions were first addressed in this context by
Lander and Waterman in a landmark study that defined the ``classic
theory'' of assembly \cite{pmid3294162}, giving estimates of the number of
contigs. At the time, genome assembly was a long term endeavour and it
made sense to gather information about the progress of the project. The
Lander-Waterman estimators are thus accurate for intermediate stages where
the number of contigs is high, but their quality drops when the assembly
nears completion.

Nowadays, genome assembly is several orders of magnitude faster. The
questions remain the same, but in many cases the assembly does not have a
proper intermediate stage because the sequencing capacity of a single run
is potentially sufficient to assemble the target genome. It is thus
desirable to minimize the amount of resources that a necessary for the
task, and estimators that are accurate when assembly is likely to be
possible are generally more useful. Likewise, the parameters of the
algorithm must minimize the risk of misassembly while giving the highest
chance that assembly will be possible. This can be done efficiently only
if the statistical properties of the assembly are also understood when it
is likely to be possible.

These are asymptotic estimates, which means that unlike the classical
estimators, they get more accurate when the number of reads increases. In
practice, they are accurate to within 1\% even for a few hundred reads
taken from a genome of a few hunder nucleotides.

All the results shown here are based on original proofs using analytic
combinatorics \cite{AnalComb2009}. The general strategy of analytic
combinatorics is to (i) describe simple combinatorial objects by a
generating function (ii) use simple mathematical operations to find the
generating function of complex structures based on these objects and (iii)
analyze the singularities of the resulting function to derive asymptotic
estimates. This method is sometimes considered counter-intuitive because
generating functions do not directly appeal to intuition
\cite{AnalComb1996}, but it allows to derive precise estimates with simple
proofs.

Since I expect most readers to not be familiar with analytic
combinatorics, I have tried to introduce the ideas progressively, hoping
that the logic of each step will be apparent. This also means that the
information is somewhat spread throughout the manuscript and does not
clearly separate the biological and the mathematical concepts. I have also
tried to use standard notations from analytic combinatorics for the proofs
of the claims, and standard notations from genomic for the specific
applications, which may be slightly confusing.  The key findings are
applications of recent results of Pemantle and Wilson on multivariate
asymptotics. The reader is referred to the original literature for the
proofs of those theorems \cite{PemWil08,AnalComb2013}.

\textbf{Related work:} Schbath and collaborators \cite{pmid10890387}
studied the effect of varying read length on the distribution of contigs.
Wendl \cite{pmid16901236} developed a theory taking into account ``edge
effects'' appearing when the read length is not negligible compared to the
size of the target genome. Stanhope \cite{pmid20686599} studied the
distribution of the largest contig using models of occupancy.


\section{Results}

\subsection{Analytic combinatorics of the assembly problem}

If $(a_{k,n})_{k \geq 0, n \geq 0}$ is a bivariate array, the generating
function of the array is by definition

\begin{equation*}
F(x,y) = \sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n}x^ky^n.
\end{equation*}

When $a_{k,n}$ counts the number of objects in a set $\mathcal{A}$, we
will say that $F(x,y)$ is the generating function of those objects. When
the emphasis is on the generating function, will refer to $a_{k,n}$ as the
``coefficient of $x^ky^n$ in $F(x,y)$'', and denote it as ``$[x^ky^n]
F(x,y)$'' when convenient. The function $F$ and the bivariate sequence
$(a_{k,n})_{k \geq 0, n \geq 0}$ carry the same information, but some
combinatorial operations are easier to perform with $F$, as we will see
below.

The first combinatorial object that we will consider is the ``interval'',
defined here as the distance between the left ends of two consecutive
reads. We will call this distance the \emph{size} of the interval, and we
will impose it to be a strictly positive integer. This means that two
reads cannot map to the same location, but we will later see how to relax
this constraint. We will also give each interval a \emph{weight} equal to
$1$. This may seem odd, but it will allow us to count intervals when we
create more complex objects.

\begin{remark}
In the fields of combinatorics, the coverage of $k$ nucleotides by $n$
intervals corresponds to a composition, \textit{i.e.} the break-down of
$k$ as a sum of $n$ positive integers \cite{AnalComb2009}. All the results
presented in this article can be interpreted more widely as properties of
compositions.
\end{remark}

We will use analytic combinatoric to derive asymptotic estimates in a
context where the results will be familiar. For this, we need to obtain
the generating function of intervals. There is exactly one interval of
size $k$ and weight 1 ($k > 0$), and zero interval in all other cases, so
$a_{k,n} = 1$ if $n = 1$ and $k > 0$, and $a_{k,n} = 0$ otherwise. The
generating function of intervals is thus

\begin{equation*}
F(x,y) = xy + x^2y + x^3y + \ldots
= xy(1+x+x^2+\ldots) = \frac{xy}{1-x}.
\end{equation*}

In this expression, we say that $x$ ``marks'' the size and that $y$
``marks'' the weight.

Operations on generating functions allow us to create more complex
combinatorial objects through mathematical operations.  We have already
used additions, which corresponds to disjoint unions. For instance, the
generating function above says that an interval is either an interval of
size 1 and weight 1, or an interval of size 2 and weight 1, or an interval
of size 3 and weight 1 \textit{etc}. More generally, if $Q(x,y)$ and
$R(x,y)$ are the generating functions of objects in disjoint sets
$\mathcal{Q}$ and $\mathcal{R}$, then $Q(x,y)+R(x,y)$ is the generating
function of objects in $\mathcal{Q} \cup \mathcal{R}$.

Multiplications correspond to Cartesian products. More specifically, if
$Q(x,y)$ and $R(x,y)$ are the generating functions of objects in sets
$\mathcal{Q}$ and $\mathcal{R}$ (disjoint or not), then $Q(x,y)R(x,y)$ is
the generating function of objects in $\mathcal{Q} \times \mathcal{R}$,
provided the attributes are \emph{additive}. For instance, we can take
both $\mathcal{Q}$ and $\mathcal{R}$ as the set of intervals. If we define
the size of a pair of intervals as the sum of their sizes (by placing the
ends next to each other) and its weight as 2, then size and weight are
additive, so the generating function of pairs of intervals is $Q(x,y)^2$.

To see this, observe that the pairs of intervals of size $k$ and weight
$n$ are made of all pairwise combinations of intervals whose sizes sum to
$k$ and weights sum to $n$. The number of such pairs is $\sum_{l=0}^k
\sum_{m=0}^n q_{l,m}q_{k-l,n-m}$ so the generating function is

\begin{equation*}
\begin{split}
\sum_{k=0}^\infty &\sum_{n=0}^\infty \left( \sum_{l=0}^k \sum_{m=0}^n
  q_{l,m}q_{k-l,n-m}\right) x^k y^n \\
&= \sum_{l=0}^\infty \sum_{m=0}^\infty \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{l,m}q_{k-l,n-m}x^{l + k-l} y^{m + n-m} \\ 
&= \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
  \sum_{k=l}^\infty \sum_{n=m}^\infty
  q_{k-l,n-m}x^{k-l} y^{n-m} \\
&= Q(x,y) \sum_{l=0}^\infty \sum_{m=0}^\infty q_{l,m} x^l y^m
 = Q(x,y)Q(x,y).
\end{split}
\end{equation*}


Applying the formula above multiple times, we see that if $A(x,y)$ is the
generating function of objects in $\mathcal{A}$, then $A(x,y)^n$ is the
generating function of objects in $\mathcal{A}^n$ (representing $n$-tuples
of objects in $\mathcal{A}$). Since joining $n$ consecutive intervals
gives a new interval whose size is the sum of individual sizes and whose
weight is the number of (atomic) intervals, $I(x,y)^n$ is the generating
function of the concatenation of $n$ intervals. It follows that the
generating function of all joined intervals is

\begin{equation}
\begin{split}
\label{eq:J}
J(x,y) &= \sum_{n=0}^\infty \left( \frac{xy}{1-x} \right)^n
= \frac{1}{1 - xy/(1-x)} \\
&= \frac{1-x}{1-x(1+y)} = (1-x) \sum_{k=0}^\infty \left(x(1+y) \right)^k.
\end{split}
\end{equation}

Using Newton's binomial formula, we can easily obtain an explicit
expression for the coefficients of $J(x,y)$, namely

\begin{equation*}
J(x,y) = (1-x)\sum_{k=0}^\infty x^k\sum_{n=0}^k {k \choose n} y^n
= \sum_{k=0}^\infty\sum_{n=0}^\infty{k \choose n} (x^ky^n - x^{k+1}y^n).
\end{equation*}

It follows that

\begin{equation}
\label{eq:coefJ}
[x^ky^n] J(x,y) =
{k \choose n} - {k-1 \choose n} = {k-1 \choose n-1}
\text{, provided $k > 0$, $n > 0$}.
\end{equation}

In the cases not covered by formula (\ref{eq:coefJ}), the coefficients are
equal to 0, except for $k = n = 0$ where the coefficient is equal to 1.

\begin{remark}
The last expression in (\ref{eq:J}) gives an alternative construction for
sequences of intervals. The term $1+y$ is the generating function of bits,
\textit{i.e.} elements of $\{0,1\}$, so $(x(1+y))^k$ is the generating
function of bit strings where $x$ marks the size. By encoding left ends of
intervals with a $1$ and all other positions with a $0$, we see that
sequences of intervals are equivalent to bit strings.
\end{remark}

In this example, we were able to obtain an explicit expression for the
number of ways that $n$ intervals can cover $k$ nucleotides. We could use
Stirling's formula to obtain the asymptotic behavior of those
coefficients, but in general this information is directly available from
the generating function.

Riordan arrays are bivariate arrays $(a_{k,n})_{k,n}$ such that the
generating function satisfies

\begin{equation*}
\sum_{k=0}^\infty \sum_{n=0}^\infty a_{k,n} x^k y^n =
\frac{\phi(x)}{1-y \nu(x)}.
\end{equation*}

Finding simple asymptotic estimates of bivariate sequences is usually not
easy, but for Riordan arrays, such results are available.

\begin{proposition}
\label{th:PW}
Assume that $F(x,y)$ is the generating function of a Riordan array, and
that $k$ and $n$ tend to infinity with $\lim k/n = \lambda$, then

\begin{equation}
\label{eq:assRA}
[x^ky^n]F(x,y) \sim \frac{\nu(x_\lambda)^n\phi(x_\lambda)}
  {x_\lambda^k\sqrt{2\pi n \sigma(x_\lambda)^2}},
\end{equation}

\noindent
where $x_\lambda$ is the solution of
$\mu(x) = x\nu'(x)/\nu(x) = \lambda$ and $\sigma(x)^2 = x \mu'(x)$.
\end{proposition}

In essence, proposition \ref{th:PW} says that if $k \sim \lambda n$ and we
can find the solution of the equation $\mu(x) = \lambda$, then we get the
symptotic growth of $a_{k,n}$. The proof of this theorem was given by
Pemantle and Wilson \cite{PemWil08,AnalComb2013}, here we only derive
concrete solutions for the practical problems under study.

\begin{remark}
Notice that expression (\ref{eq:J}) can be written as

\begin{equation*}
J(x,y) = \frac{1}{1 - yx/(1-x)}.
\end{equation*}

This form shows that $J(x,y)$ is the generating function of a Riordan
array with $\phi(x) = 1$ and $\nu(x) = x/(1-x)$. It is interesting to see
how proposition \ref{th:PW} applies to $J(x,y)$ for exposition purposes,
because $x_\lambda$ has an explicit expression in this case. Here $\nu'(x)
= 1/(1-x)^2$, $\mu(x) = 1/(1-x)$ and $\sigma^2(x) = x/(1-x)^2$, so we
obtain $x_\lambda = (\lambda -1)/\lambda$, $\nu(x_\lambda) = \lambda -1$,
and $\sigma^2(x_\lambda) = \lambda(\lambda-1)$. Combining these results
with $\lambda \sim k/n$ we obtain

\begin{equation*}
{k-1 \choose n-1} \sim \frac{k^{k-1}}{n^{n-1}(k-n)^{k-n}}
\sqrt{\frac{k}{2\pi n(k-n)}}.
\end{equation*}

This expression is a standard approximation of the binomial coefficients,
usually obtained by applying the Stirling formula.
\end{remark}
Equation (\ref{eq:J}) says that there are ${k-1 \choose n-1}$ ways to
arrange $n$ intervals so as to cover a total size $k$. However, it may not
be possible to achieve complete assembly in all cases. Only if all the
intervals are small can we merge the reads from one end to the other.  We
therefore introduce intervals of size no greater than $d$ and call them
``$d$-intervals''. Since the case $d=1$ is trivial, we will assume $d > 1$
throughout the manuscript.  Following the same rationale as bove, we find
that the generating function of $d$-intervals is $I_d(x,y) =
(x+x^2+\ldots+x^d)y$, and that the generating function of joined
$d$-intervals is

\begin{equation}
\label{eq:Jd}
J_d(x,y) = \sum_{n=0}^\infty \left(y(x+x^2+\ldots+x^d)\right)^n =
\frac{1}{1-y(x+x^2+\ldots+x^d)}.
\end{equation}

By construction, the value of $[x^ky^n]J_d(x,y)$ is the number of joined
$d$-intervals of total size $k$ and total weight $n$. These numbers are
known as the polynomial coefficients, but unfortunately they cannot be
expressed in closed form, so we will need to use an asymptotic
approximation.

\subsection{Asymptotics of Riordan arryas}


We now turn to the study of $J_d(x,y)$, where according to equation
(\ref{eq:Jd}), $\phi(x) = 1$ and $\nu(x) = x+x^2+\ldots+x^d$.

\begin{proposition}
\label{th:mu}
For $J_d(x,y)$, the equation $\mu(x) = x\nu'(x)/\nu(x) = \lambda$ has a
single solution $x_\lambda$ for $1 \leq \lambda \leq d$.
\end{proposition}

\begin{proof}
We first demonstrate that for $x \geq 0$, $\mu$ is strictly increasing.

\begin{equation}
\label{eq:mu}
\mu(x) = x\frac{\nu'(x)}{\nu(x)} =
\frac{x+2x^2+3x^3+\ldots+dx^d}{x+x^2+\ldots+x^d} =
d+\frac{1}{1-x} - \frac{d}{1-x^d}.
\end{equation} 

Differentiating the last expression we obtain

\begin{equation}
\label{eq:muprime}
\mu'(x) = \frac{1}{(1-x)^2} -\frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{equation}

The function $f(\alpha) = x^{\alpha} = e^{\alpha \log(x)}$ is strictly
convex for every $x > 0$ and $x \neq 1$. Applying the definition of
convexity, we obtain the inequality

\begin{eqnarray*}
\frac{f(0)+\ldots+f(d-1)}{d} &>&
f\left(\frac{0+1+2+\ldots+d-1}{d}\right) \\
\frac{1+x+\ldots+x^{d-1}}{d} &>& f\left(\frac{d-1}{2}\right)
= x^{(d-1)/2} \\
\frac{1-x^d}{1-x} &>& dx^{(d-1)/2} \\
\frac{1}{(1-x)^2} &>& \frac{d^2x^{d-1}}{(1-x^d)^2}.
\end{eqnarray*}

Combined with equation (\ref{eq:muprime}), the last inequality shows that
$\mu'(x) > 0$ for $x > 0$ and $x \neq 1$. Since $\mu'(0) = 1$ and $\mu'(1)
= (d+1)(d-1)/12$, $\mu$ is strictly increasing. Observing that $\mu(0) =
1$ and $\lim_{x\rightarrow\infty} \mu(x) = d$, the equation $\mu(x) =
\lambda$ has a unique solution provided $1 \leq \lambda \leq d$.
\end{proof}

\begin{remark}
The cases $\lambda > d$ and $\lambda < 1$ correspond to limits where $k >
nd$ and $k < n$, respectively. Since the size of a collection of $n$
$d$-intervals is between $n$ and $nd$, we have the trivial asymptotic
behavior $a_{k,n} = 0$ in both cases.
\end{remark}


The value of $x_\lambda$ can be found numerically using expression
(\ref{eq:mu}).  Once it is available, we can compute $\nu(x_\lambda)$ and
$\sigma(x_\lambda^2)$ from their definitions, but numeric precision can
become an issue if $n$ or $d$ is very large. To avoid this, we can use the
equivalent forms


\begin{gather}
\label{eq:nu} %% Equation for nu.
\nu(x_\lambda) = \frac{dx_\lambda}{1+(d-\lambda)(1-x_\lambda)}, \\
\label{eq:sigma} %% Equation for sigma2.
\sigma(x_\lambda)^2 = \lambda(d-\lambda) -
  \frac{d-2\lambda+1}{1-x_\lambda}.
\end{gather}


\begin{example}

Let us consider the same problem as above, with a genome of size 25,000
and 10,001 reads. We assume that the reads are drawn uniformly at random
without replacement.

As above, $k=25000$, $n=10000$, $d=25$ and $\lambda = 2.5$. We solve
equation equation (\ref{eq:mu}) with the Newton-Raphson method and obtain
$x_\lambda \approx 0.60001177$. Using equations (\ref{eq:nu}) and
(\ref{eq:sigma}) we obtain $\nu(x_\lambda) \approx 1.50006684$ and
$\sigma(x_\lambda)^2 \approx 3.747554$. We compute equation
(\ref{eq:assRA}) in logarithmic space and obtain

\begin{eqnarray*}
\log(a_{k,n}) &\approx& 10000\log(1.50006684) - 25000\log(0.60001177) \\
&-& \log(10000)/2 - \log(3.747554)/2 - \log(2\pi)/2
\approx 16819.0783
\end{eqnarray*}

We also have to compute the total number of configurations in
logarithmic space, which according to equation (\ref{eq:J}) is

\begin{equation*}
\log { 24999 \choose 9999 } \approx 16819.1067
\end{equation*}

The estimated probability that a configuration corresponds to a coverage
by $25$-intervals is
thus

\begin{equation*}
\exp(16819.0783-16819.1067) \approx 0.972.
\end{equation*}

Random simulations with 10,000 samples gave an estimate for this
probability equal to $0.973$, again very close to the numerical
approximation. In this example, $x_\lambda$ and $\nu_*(x_\lambda)$ must be
approximated to eight digits to obtain an approximate accute to within
1\%. On real problems, $n$ and $k$ can be several orders of magnitude
higher, which shows the importance of using numerically accurate formulas.

\end{example}

It is possible to remove duplicate reads, but it would be useful to know
upfront how many unique reads we expect. If there are $k+1$ possible
locations and $n+1$ reads, each position is sampled on average
$(n+1)/(k+1)$ times. Using the Poisson approximation, the probability that
a position is not sampled is $e^{-(n+1)/(k+1)}$ so that the frequency of
sampled positions is $1-e^{-(n+1)/(k+1)}$.


\begin{example}

Once again we consider a problem with a genome of size 25,000 and 10,001
reads. We assume that the reads are drawn uniformly at random with
replacement.

As above, $k=25000$ and $d=25$, but we need to replace $n=10000$ by the
estimated number of unique reads $n_* = 25000 \cdot e^{-10001/25001} =
8241.999 \approx 8242$. This give a value for $\lambda$ approximately
equal to 3.033. We follow the same calculations as in the previous example
and we obtain $x_\lambda \approx 0.67044393$, $\nu_*(x_\lambda) \approx
2.03429224$ and $\sigma_*(x_\lambda)^2 \approx 6.144598$.

\begin{eqnarray*}
\log(a_{k,n}) &\approx& 8242\log(2.03429224) - 25000\log(0.67044393) \\
&-& \log(8242)/2 - \log(6.144598)/2 - \log(2\pi)/2
\approx 15842.084.
\end{eqnarray*}

The total number of configurations in logarithmic space is again
obtained from equation (\ref{eq:Cstar}) as

\begin{equation*}
\log { 24999 \choose 8241 } \approx 15842.457.
\end{equation*}

Finally, the estimated probability that a configuration corresponds to a
coverage by $25$-intervals is

\begin{equation*}
\exp(15842.084-15842.457) \approx 0.689.
\end{equation*}

For comparison, random simulations with 10,000 samples gave an estimate
for this probability equal to $0.688$.

\end{example}

In summary, the asymptotic estimates are accurate in the range where they
are useful, namely when the probability of covering the genome is not
exceedingly close to 0 or to 1.

\subsection{The average number of contigs}
\label{sec:av}

We now introduce $d$-gaps as intervals of size greater than $d$. The same
way as we used $y$ to mark $d$-intervals, we will use $z$ to mark
$d$-gaps. In other words the generating function of $d$-gaps is

\begin{equation*}
G_d(x,z) = yz(x^{d+1}+x^{d+2}+\ldots) = yz\frac{x^{d+1}}{1-x}.
\end{equation*}

By joining $d$-intervals or $d$-gaps we obtain the configuration of an
assembly problem, with generating function

\begin{equation*}
\begin{split}
A(x,y,z) &= \sum_{n=0}^\infty \left(J_d(x,y) + G_d(x,z) \right) \\
&= \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
yz\frac{x^{d+1}}{1-x}\right)^n =
\frac{1-x}{1-x-y\left(x(1-x^d) +zx^{d+1}\right)}.
\end{split}
\end{equation*}

$A(x,y,z)$ is the generating function of a three-dimensional array
$(a_{k,n,m})$, where each term is the number of configurations of total
size $k$ with $n$ $d$-intervals and $m$ $d$-gaps. The average number of
$d$-gaps for a given value $k$ and $n$ is

\begin{equation}
\label{eq:average}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m}.
\end{equation}

To compute the generating function of the denomiator of
(\ref{eq:average}), observe that

\begin{equation*}
A(x,y,1) = \sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty a_{k,n,m}\right) x^ky^n.
\end{equation*}

So by setting $z$ to 1, we obtain the generating function of the
denominator of (\ref{eq:average}) as

\begin{equation*}
\frac{1-x}{1-x-xy} = \frac{1}{1-yx/(1-x)} = J(x,y).
\end{equation*}

Even though we know the coefficients of this generating function, we will
not need them to obtain a simple asymptotic approximation of
(\ref{eq:average}). To compute the numerator of (\ref{eq:average}), we
differentiate $A(x,y,z)$ with respect to $z$ and we observe that

\begin{equation*}
\frac{\partial A(x,y,z)}{\partial z}\Bigr|_{\substack{\\z=1}} =
\sum_{k=0}^\infty\sum_{n=0}^\infty
\left(\sum_{m=0}^\infty ma_{k,n,m}\right) x^ky^n.
\end{equation*}

So by differentiating $A(x,y,z)$ and settig $z$ to 1, we obtain the
generating function of the numerator of (\ref{eq:average}) as

\begin{equation*}
\frac{yx^{d+1}(1-x)}{\left(1-x-xy\right)^2}.
\end{equation*}

This is not the generating function of a Riordan array, but observe that
it is equal to $y\partial D(x,y)/\partial y$, where

\begin{equation*}
D(x,y) = \frac{x^d(1-x)}{1-x-xy} =
\frac{x^d}{1-yx/(1-x)}.
\end{equation*}

$D(x,y)$ is the generating function of a Riordan array with $\phi(x) =
x^d$ and $\nu(x) = x/(1-x)$. We can obtain obtain accurate asymptotic
estimates of $[x^ky^n]D(x,y)$, and since $[x^ky^n]y\partial D(x,y) /
\partial y = n[x^ky^n]D(x,y)$, we can also obtain accurate asymptotics for
the numerator of (\ref{eq:average}).

We also note that the function $\nu$ is the same for $J(x,y)$ and
$D(x,y)$, so according to proposition \ref{th:PW}, the values of
$x_\lambda$, $\nu(x_\lambda)$ and $\sigma(x_\lambda)^2$ are the same in
both cases. This implies that

\begin{equation*}
\sum_{m=0}^\infty ma_{k,n,m}\Big/\sum_{m=0}^\infty a_{k,n,m} \sim
n x_\lambda^d.
\end{equation*}

We have seen in the remark after proposition \ref{th:PW} that $x_\lambda =
(\lambda-1)/\lambda$, so the average number of gaps is $n(1-1/\lambda)^d$,
which we can express the general form

\begin{equation*}
n\left(1-n/k\right)^d.
\end{equation*}

\begin{example}
Consider a genome of size 25,000 and 5,001 reads. Here $k = $ and $n =
5000$ (so $\lambda = 5$) and $d = 25$. We obtain $x_\lambda = 0.8$
and $n x_\lambda^d \approx 18.89$. The simulations give
$18.85$. In comparison, the Lander-Waterman estimate is $ne^{-nd/k} =
33.69$.
\end{example}

\subsection{The average size of contigs}

In the section above, $z$ was used to mark gaps. Here we will use it to
mark their size, so the generating function of $d$-gaps will be defined as
$x^{d+1}z^{d+1} + x^{d+2}z^{d+2} + \ldots = x^{d+1}z^{d+1}/(1-xz)$.

\begin{equation*}
\tilde{A}_d(x,y,z) = \sum_{n=0}^\infty \left(xy\frac{1-x^d}{1-x} +
y\frac{x^{d+1}z^{d+1}}{1-xz}\right)^n =
\frac{1}{1-y \left(x\frac{1-x^d}{1-x} +
\frac{x^{d+1}z^{d+1}}{1-xz} \right)}.
\end{equation*}

\begin{equation*}
\frac{\partial\tilde{A}_d(x,y,z)}{\partial z}\Bigr|_{\substack{\\z=1}} =
\sum_{k=0}^\infty\sum_{n=0}^\infty
\end{equation*}


%---------------------------------------------------------------
%---------------------------------------------------------------

\bibliography{pubmed,extra}
\bibliographystyle{plain}

%----------------------------------------------------------------

\end{document}
